{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Image Colorization\n",
    "\n",
    "Based on [Let there be Color!](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# DEKLARACJA !!!\n",
    "# PRACY INŻ !!!!!!!!\n",
    "# DO PIĄTKU !!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from skimage import color, io\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "img_dir_train ='./data/food41-120-train/'\n",
    "img_dir_test = './data/food41-120-test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [x] convert dataset to tensor? (now: numpy array)\n",
    " - seems like dataloader does it automatically - but doesnt swap axes\n",
    " - transforms.toTensor does the job\n",
    "- [x] normialize data?\n",
    " - only $ab$ channel + L channel\n",
    "- [ ] transform images? - random crops itp\n",
    "- [ ] deal with `torch.set_default_tensor_type('torch.DoubleTensor')` or `torch.FloatTensor`\n",
    "- [x] refector asserts so they work with batch sizes different than 4\n",
    "- [ ] shuffle data (trainloader)\n",
    "- [ ] refactor?? - separate files\n",
    "- [x] load / save model\n",
    "- [x] extract hyperparameters\n",
    "- [x] load whole dataset to memory\n",
    "- [ ] read/write to zip\n",
    "- [ ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom dateset\n",
    "\n",
    "- One needs to [swap axes](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms)\n",
    "    - numpy image: H x W x C\n",
    "    - torch image: C X H X W\n",
    "\n",
    "\n",
    "- Quick fact: $L \\in [0, 100]$, $a \\in [-127, 128]$, $b \\in [-128, 127]$ [(source)](https://stackoverflow.com/questions/25294141/cielab-color-range-for-scikit-image)\n",
    "\n",
    "\n",
    "- How an image is processed:\n",
    "    1. Load i-th image to memory\n",
    "    2. Convert it to LAB Space\n",
    "    3. Convert to torch.tensor\n",
    "    4. Split the image to $L$ and $ab$ channels\n",
    "    5. Normalize $ab$ to $[0, 1]$. $L$ ~~remains unnormalized.~~ is normalized as well.\n",
    "    6. $L$ will feed net, $a'b'$ will be its output\n",
    "    7. Calculate $Loss(ab, a'b')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDateset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, all2mem=True):\n",
    "        \"\"\"\n",
    "        All images from `img_dir` will be read.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.all2mem = all2mem\n",
    "        self.img_names = [file for file in os.listdir(self.img_dir)]\n",
    "        \n",
    "        assert all([img.endswith('.jpg') for img in self.img_names]), \"Must be *.jpg\"\n",
    "        \n",
    "        if self.all2mem:\n",
    "            self.images = [io.imread(os.path.join(self.img_dir, img)) \n",
    "                           for img in self.img_names]\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get an image in Lab color space.\n",
    "        Returns a tuple (L, ab, name)\n",
    "            - `L` stands for lightness - it's the net input\n",
    "            - `ab` is chrominance - something that the net learns\n",
    "            - `name` - image filename\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.all2mem:\n",
    "            image = self.images[idx]\n",
    "        else:\n",
    "            img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
    "            image = io.imread(img_name)\n",
    "        \n",
    "        \n",
    "        assert image.shape == (224, 224, 3)\n",
    "                \n",
    "        img_lab = color.rgb2lab(image)\n",
    "        img_lab = np.transpose(img_lab, (2, 0, 1))\n",
    "        \n",
    "        assert img_lab.shape == (3, 224, 224)\n",
    "        \n",
    "        img_lab = torch.tensor( img_lab.astype(np.float32) )\n",
    "        \n",
    "        assert img_lab.shape == (3, 224, 224)\n",
    "               \n",
    "        L  = img_lab[:1,:,:]\n",
    "        ab = img_lab[1:,:,:]\n",
    "        \n",
    "        # Normalization\n",
    "        L =   L / 100.0         # 0..1\n",
    "        ab = (ab + 128.0) / 255.0 # 0..1\n",
    "              \n",
    "        assert L.shape == (1, 224, 224)\n",
    "        assert ab.shape == (2, 224, 224)\n",
    "        \n",
    "        return L, ab, self.img_names[idx]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImagesDateset(img_dir_train, all2mem=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=4)\n",
    "\n",
    "testset = ImagesDateset(img_dir_test, all2mem=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColNet(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ColNet, self).__init__()\n",
    "        \n",
    "        ksize = np.array( [1, 64, 128, 128, 256, 256, 512, 512, 256, 128, 64, 64, 32] ) // 8\n",
    "        ksize[0] = 1\n",
    "        \n",
    "        # 'Low-level features'\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,        out_channels=ksize[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=ksize[1], out_channels=ksize[2], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=ksize[2], out_channels=ksize[3], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=ksize[3], out_channels=ksize[4], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=ksize[4], out_channels=ksize[5], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=ksize[5], out_channels=ksize[6], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 'Mid-level fetures'\n",
    "        self.conv7 = nn.Conv2d(in_channels=ksize[6], out_channels=ksize[7], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=ksize[7], out_channels=ksize[8], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 'Colorization network'\n",
    "        self.conv9 = nn.Conv2d(in_channels=ksize[8], out_channels=ksize[9], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Here comes upsample #1\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(in_channels=ksize[9], out_channels=ksize[10], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(in_channels=ksize[10],out_channels=ksize[11], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Here comes upsample #2        \n",
    "        \n",
    "        self.conv12 = nn.Conv2d(in_channels=ksize[11], out_channels=ksize[12], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv13out = nn.Conv2d(in_channels=ksize[12], out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Low level\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        \n",
    "        # Mid level\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        \n",
    "        # assert x.shape[1:] == (256, 28, 28), \"おわり： mid level\"\n",
    "        \n",
    "\n",
    "        # Colorization Net\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "        # assert x.shape[1:] == (128, 28, 28), \"おわり： conv9\"\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "\n",
    "        # assert x.shape[1:] == (128, 56, 56), \"おわり： upsample1\"\n",
    "    \n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.relu(self.conv11(x))\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = torch.sigmoid(self.conv13out(x))\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "        \n",
    "        # assert x.shape[1:] == (2, 224, 224)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "Unnormalize and return RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_out2rgb(L, ab_out):\n",
    "    \"\"\"\n",
    "    L - original `L` channel\n",
    "    ab_out - learned `ab` channels which were the net's output\n",
    "    \n",
    "    Retruns: 3 channel RGB image\n",
    "    \"\"\"\n",
    "    # Convert to numpy and unnnormalize\n",
    "    L = L.numpy() * 100.0\n",
    "    \n",
    "    ab_out = np.floor(ab_out.numpy() * 255.0) - 128.0 \n",
    "    \n",
    "    # Transpose axis to HxWxC again\n",
    "    L = L.transpose((1, 2, 0))\n",
    "    ab_out = ab_out.transpose((1, 2, 0))\n",
    "\n",
    "    # Stack layers\n",
    "    lab_stack = np.dstack((L, ab_out))\n",
    "    \n",
    "    return color.lab2rgb(lab_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1 | batch: 1] loss: 1725.632\n",
      "[epoch: 1 | batch: 2] loss: 1774.514\n",
      "[epoch: 1 | batch: 3] loss: 1319.859\n",
      "[epoch: 1 | batch: 4] loss: 1445.086\n",
      "[epoch: 1 | batch: 5] loss: 1338.139\n",
      "[epoch: 1 | batch: 6] loss: 1581.826\n",
      "[epoch: 1 | batch: 7] loss: 1346.652\n",
      "[epoch: 1 | batch: 8] loss: 1549.567\n",
      "[epoch: 1 | batch: 9] loss: 1141.875\n",
      "[epoch: 1 | batch: 10] loss: 1079.381\n",
      "[epoch: 1 | batch: 11] loss: 1222.143\n",
      "[epoch: 1 | batch: 12] loss: 742.058\n",
      "[epoch: 1 | batch: 13] loss: 455.419\n",
      "mean epoch loss: 1286.32\n",
      "saved model to ./model/colnet181105-21-29-32.pt\n",
      "End of epoch 1\n",
      "\n",
      "[epoch: 2 | batch: 1] loss: 854.145\n",
      "[epoch: 2 | batch: 2] loss: 816.064\n",
      "[epoch: 2 | batch: 3] loss: 655.662\n",
      "[epoch: 2 | batch: 4] loss: 700.462\n",
      "[epoch: 2 | batch: 5] loss: 748.077\n",
      "[epoch: 2 | batch: 6] loss: 910.888\n",
      "[epoch: 2 | batch: 7] loss: 779.830\n",
      "[epoch: 2 | batch: 8] loss: 891.541\n",
      "[epoch: 2 | batch: 9] loss: 595.433\n",
      "[epoch: 2 | batch: 10] loss: 613.256\n",
      "[epoch: 2 | batch: 11] loss: 574.222\n",
      "[epoch: 2 | batch: 12] loss: 612.704\n",
      "[epoch: 2 | batch: 13] loss: 325.295\n",
      "mean epoch loss: 698.28\n",
      "saved model to ./model/colnet181105-21-29-36.pt\n",
      "End of epoch 2\n",
      "\n",
      "[epoch: 3 | batch: 1] loss: 501.608\n",
      "[epoch: 3 | batch: 2] loss: 531.750\n",
      "[epoch: 3 | batch: 3] loss: 530.072\n",
      "[epoch: 3 | batch: 4] loss: 681.069\n",
      "[epoch: 3 | batch: 5] loss: 597.660\n",
      "[epoch: 3 | batch: 6] loss: 739.596\n",
      "[epoch: 3 | batch: 7] loss: 629.961\n",
      "[epoch: 3 | batch: 8] loss: 662.026\n",
      "[epoch: 3 | batch: 9] loss: 488.885\n",
      "[epoch: 3 | batch: 10] loss: 585.618\n",
      "[epoch: 3 | batch: 11] loss: 527.519\n",
      "[epoch: 3 | batch: 12] loss: 567.393\n",
      "[epoch: 3 | batch: 13] loss: 262.327\n",
      "mean epoch loss: 561.96\n",
      "saved model to ./model/colnet181105-21-29-40.pt\n",
      "End of epoch 3\n",
      "\n",
      "[epoch: 4 | batch: 1] loss: 496.960\n",
      "[epoch: 4 | batch: 2] loss: 499.759\n",
      "[epoch: 4 | batch: 3] loss: 524.577\n",
      "[epoch: 4 | batch: 4] loss: 742.860\n",
      "[epoch: 4 | batch: 5] loss: 583.007\n",
      "[epoch: 4 | batch: 6] loss: 723.764\n",
      "[epoch: 4 | batch: 7] loss: 619.197\n",
      "[epoch: 4 | batch: 8] loss: 644.460\n",
      "[epoch: 4 | batch: 9] loss: 493.655\n",
      "[epoch: 4 | batch: 10] loss: 582.333\n",
      "[epoch: 4 | batch: 11] loss: 556.168\n",
      "[epoch: 4 | batch: 12] loss: 540.832\n",
      "[epoch: 4 | batch: 13] loss: 259.068\n",
      "mean epoch loss: 558.97\n",
      "saved model to ./model/colnet181105-21-29-45.pt\n",
      "End of epoch 4\n",
      "\n",
      "[epoch: 5 | batch: 1] loss: 491.958\n",
      "[epoch: 5 | batch: 2] loss: 496.674\n",
      "[epoch: 5 | batch: 3] loss: 562.194\n",
      "[epoch: 5 | batch: 4] loss: 758.741\n",
      "[epoch: 5 | batch: 5] loss: 586.552\n",
      "[epoch: 5 | batch: 6] loss: 713.639\n",
      "[epoch: 5 | batch: 7] loss: 616.394\n",
      "[epoch: 5 | batch: 8] loss: 661.420\n",
      "[epoch: 5 | batch: 9] loss: 506.801\n",
      "[epoch: 5 | batch: 10] loss: 587.716\n",
      "[epoch: 5 | batch: 11] loss: 589.258\n",
      "[epoch: 5 | batch: 12] loss: 528.039\n",
      "[epoch: 5 | batch: 13] loss: 268.257\n",
      "mean epoch loss: 566.74\n",
      "saved model to ./model/colnet181105-21-29-51.pt\n",
      "End of epoch 5\n",
      "\n",
      "[epoch: 6 | batch: 1] loss: 485.378\n",
      "[epoch: 6 | batch: 2] loss: 505.739\n",
      "[epoch: 6 | batch: 3] loss: 604.141\n",
      "[epoch: 6 | batch: 4] loss: 783.201\n",
      "[epoch: 6 | batch: 5] loss: 601.269\n",
      "[epoch: 6 | batch: 6] loss: 699.371\n",
      "[epoch: 6 | batch: 7] loss: 608.609\n",
      "[epoch: 6 | batch: 8] loss: 669.539\n",
      "[epoch: 6 | batch: 9] loss: 517.321\n",
      "[epoch: 6 | batch: 10] loss: 597.002\n",
      "[epoch: 6 | batch: 11] loss: 629.877\n",
      "[epoch: 6 | batch: 12] loss: 532.400\n",
      "[epoch: 6 | batch: 13] loss: 291.647\n",
      "mean epoch loss: 578.88\n",
      "saved model to ./model/colnet181105-21-29-55.pt\n",
      "End of epoch 6\n",
      "\n",
      "[epoch: 7 | batch: 1] loss: 500.084\n",
      "[epoch: 7 | batch: 2] loss: 493.870\n",
      "[epoch: 7 | batch: 3] loss: 569.069\n",
      "[epoch: 7 | batch: 4] loss: 820.324\n",
      "[epoch: 7 | batch: 5] loss: 656.626\n",
      "[epoch: 7 | batch: 6] loss: 673.772\n",
      "[epoch: 7 | batch: 7] loss: 581.565\n",
      "[epoch: 7 | batch: 8] loss: 609.774\n",
      "[epoch: 7 | batch: 9] loss: 491.837\n",
      "[epoch: 7 | batch: 10] loss: 587.212\n",
      "[epoch: 7 | batch: 11] loss: 621.541\n",
      "[epoch: 7 | batch: 12] loss: 534.221\n",
      "[epoch: 7 | batch: 13] loss: 305.586\n",
      "mean epoch loss: 572.73\n",
      "saved model to ./model/colnet181105-21-30-00.pt\n",
      "End of epoch 7\n",
      "\n",
      "[epoch: 8 | batch: 1] loss: 531.856\n",
      "[epoch: 8 | batch: 2] loss: 513.165\n",
      "[epoch: 8 | batch: 3] loss: 501.243\n",
      "[epoch: 8 | batch: 4] loss: 771.634\n",
      "[epoch: 8 | batch: 5] loss: 667.135\n",
      "[epoch: 8 | batch: 6] loss: 680.554\n",
      "[epoch: 8 | batch: 7] loss: 583.677\n",
      "[epoch: 8 | batch: 8] loss: 567.203\n",
      "[epoch: 8 | batch: 9] loss: 473.136\n",
      "[epoch: 8 | batch: 10] loss: 573.549\n",
      "[epoch: 8 | batch: 11] loss: 581.744\n",
      "[epoch: 8 | batch: 12] loss: 523.229\n",
      "[epoch: 8 | batch: 13] loss: 302.467\n",
      "mean epoch loss: 559.28\n",
      "saved model to ./model/colnet181105-21-30-03.pt\n",
      "End of epoch 8\n",
      "\n",
      "[epoch: 9 | batch: 1] loss: 536.933\n",
      "[epoch: 9 | batch: 2] loss: 527.519\n",
      "[epoch: 9 | batch: 3] loss: 474.854\n",
      "[epoch: 9 | batch: 4] loss: 722.136\n",
      "[epoch: 9 | batch: 5] loss: 640.960\n",
      "[epoch: 9 | batch: 6] loss: 679.367\n",
      "[epoch: 9 | batch: 7] loss: 590.638\n",
      "[epoch: 9 | batch: 8] loss: 550.063\n",
      "[epoch: 9 | batch: 9] loss: 470.601\n",
      "[epoch: 9 | batch: 10] loss: 573.863\n",
      "[epoch: 9 | batch: 11] loss: 558.792\n",
      "[epoch: 9 | batch: 12] loss: 517.403\n",
      "[epoch: 9 | batch: 13] loss: 295.178\n",
      "mean epoch loss: 549.10\n",
      "saved model to ./model/colnet181105-21-30-07.pt\n",
      "End of epoch 9\n",
      "\n",
      "[epoch: 10 | batch: 1] loss: 533.741\n",
      "[epoch: 10 | batch: 2] loss: 526.938\n",
      "[epoch: 10 | batch: 3] loss: 469.107\n",
      "[epoch: 10 | batch: 4] loss: 706.257\n",
      "[epoch: 10 | batch: 5] loss: 623.535\n",
      "[epoch: 10 | batch: 6] loss: 675.279\n",
      "[epoch: 10 | batch: 7] loss: 591.286\n",
      "[epoch: 10 | batch: 8] loss: 541.882\n",
      "[epoch: 10 | batch: 9] loss: 470.001\n",
      "[epoch: 10 | batch: 10] loss: 576.650\n",
      "[epoch: 10 | batch: 11] loss: 542.622\n",
      "[epoch: 10 | batch: 12] loss: 513.935\n",
      "[epoch: 10 | batch: 13] loss: 289.869\n",
      "mean epoch loss: 543.16\n",
      "saved model to ./model/colnet181105-21-30-11.pt\n",
      "End of epoch 10\n",
      "\n",
      "[epoch: 11 | batch: 1] loss: 530.176\n",
      "[epoch: 11 | batch: 2] loss: 514.741\n",
      "[epoch: 11 | batch: 3] loss: 479.916\n",
      "[epoch: 11 | batch: 4] loss: 723.753\n",
      "[epoch: 11 | batch: 5] loss: 622.331\n",
      "[epoch: 11 | batch: 6] loss: 668.597\n",
      "[epoch: 11 | batch: 7] loss: 574.957\n",
      "[epoch: 11 | batch: 8] loss: 552.971\n",
      "[epoch: 11 | batch: 9] loss: 463.210\n",
      "[epoch: 11 | batch: 10] loss: 573.246\n",
      "[epoch: 11 | batch: 11] loss: 544.689\n",
      "[epoch: 11 | batch: 12] loss: 513.726\n",
      "[epoch: 11 | batch: 13] loss: 275.878\n",
      "mean epoch loss: 541.40\n",
      "saved model to ./model/colnet181105-21-30-15.pt\n",
      "End of epoch 11\n",
      "\n",
      "[epoch: 12 | batch: 1] loss: 498.265\n",
      "[epoch: 12 | batch: 2] loss: 481.767\n",
      "[epoch: 12 | batch: 3] loss: 507.122\n",
      "[epoch: 12 | batch: 4] loss: 765.070\n",
      "[epoch: 12 | batch: 5] loss: 616.750\n",
      "[epoch: 12 | batch: 6] loss: 666.192\n",
      "[epoch: 12 | batch: 7] loss: 572.739\n",
      "[epoch: 12 | batch: 8] loss: 567.653\n",
      "[epoch: 12 | batch: 9] loss: 468.195\n",
      "[epoch: 12 | batch: 10] loss: 575.098\n",
      "[epoch: 12 | batch: 11] loss: 570.185\n",
      "[epoch: 12 | batch: 12] loss: 518.507\n",
      "[epoch: 12 | batch: 13] loss: 285.696\n",
      "mean epoch loss: 545.63\n",
      "saved model to ./model/colnet181105-21-30-19.pt\n",
      "End of epoch 12\n",
      "\n",
      "[epoch: 13 | batch: 1] loss: 511.854\n",
      "[epoch: 13 | batch: 2] loss: 493.544\n",
      "[epoch: 13 | batch: 3] loss: 485.945\n",
      "[epoch: 13 | batch: 4] loss: 742.768\n",
      "[epoch: 13 | batch: 5] loss: 637.940\n",
      "[epoch: 13 | batch: 6] loss: 667.143\n",
      "[epoch: 13 | batch: 7] loss: 582.079\n",
      "[epoch: 13 | batch: 8] loss: 537.052\n",
      "[epoch: 13 | batch: 9] loss: 460.639\n",
      "[epoch: 13 | batch: 10] loss: 570.688\n",
      "[epoch: 13 | batch: 11] loss: 557.315\n",
      "[epoch: 13 | batch: 12] loss: 516.378\n",
      "[epoch: 13 | batch: 13] loss: 292.877\n",
      "mean epoch loss: 542.79\n",
      "saved model to ./model/colnet181105-21-30-23.pt\n",
      "End of epoch 13\n",
      "\n",
      "[epoch: 14 | batch: 1] loss: 535.887\n",
      "[epoch: 14 | batch: 2] loss: 516.802\n",
      "[epoch: 14 | batch: 3] loss: 462.880\n",
      "[epoch: 14 | batch: 4] loss: 703.476\n",
      "[epoch: 14 | batch: 5] loss: 609.954\n",
      "[epoch: 14 | batch: 6] loss: 662.472\n",
      "[epoch: 14 | batch: 7] loss: 591.159\n",
      "[epoch: 14 | batch: 8] loss: 520.351\n",
      "[epoch: 14 | batch: 9] loss: 462.168\n",
      "[epoch: 14 | batch: 10] loss: 575.279\n",
      "[epoch: 14 | batch: 11] loss: 528.062\n",
      "[epoch: 14 | batch: 12] loss: 510.627\n",
      "[epoch: 14 | batch: 13] loss: 285.683\n",
      "mean epoch loss: 535.75\n",
      "saved model to ./model/colnet181105-21-30-27.pt\n",
      "End of epoch 14\n",
      "\n",
      "[epoch: 15 | batch: 1] loss: 537.107\n",
      "[epoch: 15 | batch: 2] loss: 517.327\n",
      "[epoch: 15 | batch: 3] loss: 459.208\n",
      "[epoch: 15 | batch: 4] loss: 690.894\n",
      "[epoch: 15 | batch: 5] loss: 585.068\n",
      "[epoch: 15 | batch: 6] loss: 655.803\n",
      "[epoch: 15 | batch: 7] loss: 586.585\n",
      "[epoch: 15 | batch: 8] loss: 512.434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 15 | batch: 9] loss: 460.988\n",
      "[epoch: 15 | batch: 10] loss: 579.382\n",
      "[epoch: 15 | batch: 11] loss: 516.359\n",
      "[epoch: 15 | batch: 12] loss: 508.368\n",
      "[epoch: 15 | batch: 13] loss: 279.195\n",
      "mean epoch loss: 529.90\n",
      "saved model to ./model/colnet181105-21-30-31.pt\n",
      "End of epoch 15\n",
      "\n",
      "[epoch: 16 | batch: 1] loss: 528.261\n",
      "[epoch: 16 | batch: 2] loss: 507.688\n",
      "[epoch: 16 | batch: 3] loss: 460.588\n",
      "[epoch: 16 | batch: 4] loss: 693.373\n",
      "[epoch: 16 | batch: 5] loss: 576.638\n",
      "[epoch: 16 | batch: 6] loss: 652.002\n",
      "[epoch: 16 | batch: 7] loss: 581.992\n",
      "[epoch: 16 | batch: 8] loss: 508.949\n",
      "[epoch: 16 | batch: 9] loss: 456.977\n",
      "[epoch: 16 | batch: 10] loss: 578.102\n",
      "[epoch: 16 | batch: 11] loss: 515.350\n",
      "[epoch: 16 | batch: 12] loss: 507.599\n",
      "[epoch: 16 | batch: 13] loss: 277.425\n",
      "mean epoch loss: 526.53\n",
      "saved model to ./model/colnet181105-21-30-35.pt\n",
      "End of epoch 16\n",
      "\n",
      "[epoch: 17 | batch: 1] loss: 523.985\n",
      "[epoch: 17 | batch: 2] loss: 502.058\n",
      "[epoch: 17 | batch: 3] loss: 462.033\n",
      "[epoch: 17 | batch: 4] loss: 697.191\n",
      "[epoch: 17 | batch: 5] loss: 572.026\n",
      "[epoch: 17 | batch: 6] loss: 649.437\n",
      "[epoch: 17 | batch: 7] loss: 579.610\n",
      "[epoch: 17 | batch: 8] loss: 505.530\n",
      "[epoch: 17 | batch: 9] loss: 453.477\n",
      "[epoch: 17 | batch: 10] loss: 576.669\n",
      "[epoch: 17 | batch: 11] loss: 515.437\n",
      "[epoch: 17 | batch: 12] loss: 507.503\n",
      "[epoch: 17 | batch: 13] loss: 278.186\n",
      "mean epoch loss: 524.86\n",
      "saved model to ./model/colnet181105-21-30-39.pt\n",
      "End of epoch 17\n",
      "\n",
      "[epoch: 18 | batch: 1] loss: 523.128\n",
      "[epoch: 18 | batch: 2] loss: 497.092\n",
      "[epoch: 18 | batch: 3] loss: 464.628\n",
      "[epoch: 18 | batch: 4] loss: 703.313\n",
      "[epoch: 18 | batch: 5] loss: 572.431\n",
      "[epoch: 18 | batch: 6] loss: 647.615\n",
      "[epoch: 18 | batch: 7] loss: 577.981\n",
      "[epoch: 18 | batch: 8] loss: 504.482\n",
      "[epoch: 18 | batch: 9] loss: 452.300\n",
      "[epoch: 18 | batch: 10] loss: 573.726\n",
      "[epoch: 18 | batch: 11] loss: 518.901\n",
      "[epoch: 18 | batch: 12] loss: 506.212\n",
      "[epoch: 18 | batch: 13] loss: 277.435\n",
      "mean epoch loss: 524.56\n",
      "saved model to ./model/colnet181105-21-30-43.pt\n",
      "End of epoch 18\n",
      "\n",
      "[epoch: 19 | batch: 1] loss: 521.708\n",
      "[epoch: 19 | batch: 2] loss: 496.746\n",
      "[epoch: 19 | batch: 3] loss: 463.920\n",
      "[epoch: 19 | batch: 4] loss: 702.795\n",
      "[epoch: 19 | batch: 5] loss: 568.656\n",
      "[epoch: 19 | batch: 6] loss: 644.951\n",
      "[epoch: 19 | batch: 7] loss: 576.939\n",
      "[epoch: 19 | batch: 8] loss: 499.716\n",
      "[epoch: 19 | batch: 9] loss: 450.245\n",
      "[epoch: 19 | batch: 10] loss: 572.740\n",
      "[epoch: 19 | batch: 11] loss: 517.398\n",
      "[epoch: 19 | batch: 12] loss: 504.696\n",
      "[epoch: 19 | batch: 13] loss: 276.225\n",
      "mean epoch loss: 522.83\n",
      "saved model to ./model/colnet181105-21-30-47.pt\n",
      "End of epoch 19\n",
      "\n",
      "[epoch: 20 | batch: 1] loss: 515.466\n",
      "[epoch: 20 | batch: 2] loss: 488.640\n",
      "[epoch: 20 | batch: 3] loss: 468.361\n",
      "[epoch: 20 | batch: 4] loss: 710.993\n",
      "[epoch: 20 | batch: 5] loss: 571.727\n",
      "[epoch: 20 | batch: 6] loss: 644.077\n",
      "[epoch: 20 | batch: 7] loss: 574.773\n",
      "[epoch: 20 | batch: 8] loss: 504.238\n",
      "[epoch: 20 | batch: 9] loss: 451.312\n",
      "[epoch: 20 | batch: 10] loss: 570.258\n",
      "[epoch: 20 | batch: 11] loss: 523.130\n",
      "[epoch: 20 | batch: 12] loss: 504.664\n",
      "[epoch: 20 | batch: 13] loss: 274.535\n",
      "mean epoch loss: 523.24\n",
      "saved model to ./model/colnet181105-21-30-51.pt\n",
      "End of epoch 20\n",
      "\n",
      "[epoch: 21 | batch: 1] loss: 518.809\n",
      "[epoch: 21 | batch: 2] loss: 495.976\n",
      "[epoch: 21 | batch: 3] loss: 463.144\n",
      "[epoch: 21 | batch: 4] loss: 701.373\n",
      "[epoch: 21 | batch: 5] loss: 557.699\n",
      "[epoch: 21 | batch: 6] loss: 639.987\n",
      "[epoch: 21 | batch: 7] loss: 572.208\n",
      "[epoch: 21 | batch: 8] loss: 478.054\n",
      "[epoch: 21 | batch: 9] loss: 456.730\n",
      "[epoch: 21 | batch: 10] loss: 561.494\n",
      "[epoch: 21 | batch: 11] loss: 512.676\n",
      "[epoch: 21 | batch: 12] loss: 497.254\n",
      "[epoch: 21 | batch: 13] loss: 258.559\n",
      "mean epoch loss: 516.46\n",
      "saved model to ./model/colnet181105-21-30-55.pt\n",
      "End of epoch 21\n",
      "\n",
      "[epoch: 22 | batch: 1] loss: 494.413\n",
      "[epoch: 22 | batch: 2] loss: 468.890\n",
      "[epoch: 22 | batch: 3] loss: 485.863\n",
      "[epoch: 22 | batch: 4] loss: 718.547\n",
      "[epoch: 22 | batch: 5] loss: 545.646\n",
      "[epoch: 22 | batch: 6] loss: 638.375\n",
      "[epoch: 22 | batch: 7] loss: 562.922\n",
      "[epoch: 22 | batch: 8] loss: 506.727\n",
      "[epoch: 22 | batch: 9] loss: 446.704\n",
      "[epoch: 22 | batch: 10] loss: 571.541\n",
      "[epoch: 22 | batch: 11] loss: 521.207\n",
      "[epoch: 22 | batch: 12] loss: 506.360\n",
      "[epoch: 22 | batch: 13] loss: 263.100\n",
      "mean epoch loss: 517.71\n",
      "saved model to ./model/colnet181105-21-30-59.pt\n",
      "End of epoch 22\n",
      "\n",
      "[epoch: 23 | batch: 1] loss: 503.797\n",
      "[epoch: 23 | batch: 2] loss: 470.081\n",
      "[epoch: 23 | batch: 3] loss: 487.627\n",
      "[epoch: 23 | batch: 4] loss: 734.052\n",
      "[epoch: 23 | batch: 5] loss: 556.786\n",
      "[epoch: 23 | batch: 6] loss: 637.472\n",
      "[epoch: 23 | batch: 7] loss: 566.151\n",
      "[epoch: 23 | batch: 8] loss: 501.379\n",
      "[epoch: 23 | batch: 9] loss: 446.587\n",
      "[epoch: 23 | batch: 10] loss: 569.687\n",
      "[epoch: 23 | batch: 11] loss: 528.101\n",
      "[epoch: 23 | batch: 12] loss: 507.511\n",
      "[epoch: 23 | batch: 13] loss: 267.707\n",
      "mean epoch loss: 521.30\n",
      "saved model to ./model/colnet181105-21-31-03.pt\n",
      "End of epoch 23\n",
      "\n",
      "[epoch: 24 | batch: 1] loss: 513.013\n",
      "[epoch: 24 | batch: 2] loss: 479.589\n",
      "[epoch: 24 | batch: 3] loss: 475.890\n",
      "[epoch: 24 | batch: 4] loss: 722.125\n",
      "[epoch: 24 | batch: 5] loss: 554.619\n",
      "[epoch: 24 | batch: 6] loss: 636.986\n",
      "[epoch: 24 | batch: 7] loss: 572.110\n",
      "[epoch: 24 | batch: 8] loss: 487.540\n",
      "[epoch: 24 | batch: 9] loss: 444.193\n",
      "[epoch: 24 | batch: 10] loss: 571.047\n",
      "[epoch: 24 | batch: 11] loss: 518.597\n",
      "[epoch: 24 | batch: 12] loss: 507.074\n",
      "[epoch: 24 | batch: 13] loss: 269.472\n",
      "mean epoch loss: 519.40\n",
      "saved model to ./model/colnet181105-21-31-06.pt\n",
      "End of epoch 24\n",
      "\n",
      "[epoch: 25 | batch: 1] loss: 522.365\n",
      "[epoch: 25 | batch: 2] loss: 489.590\n",
      "[epoch: 25 | batch: 3] loss: 466.922\n",
      "[epoch: 25 | batch: 4] loss: 705.670\n",
      "[epoch: 25 | batch: 5] loss: 547.226\n",
      "[epoch: 25 | batch: 6] loss: 636.143\n",
      "[epoch: 25 | batch: 7] loss: 577.270\n",
      "[epoch: 25 | batch: 8] loss: 480.315\n",
      "[epoch: 25 | batch: 9] loss: 445.987\n",
      "[epoch: 25 | batch: 10] loss: 571.254\n",
      "[epoch: 25 | batch: 11] loss: 512.674\n",
      "[epoch: 25 | batch: 12] loss: 501.472\n",
      "[epoch: 25 | batch: 13] loss: 266.431\n",
      "mean epoch loss: 517.18\n",
      "saved model to ./model/colnet181105-21-31-10.pt\n",
      "End of epoch 25\n",
      "\n",
      "[epoch: 26 | batch: 1] loss: 522.165\n",
      "[epoch: 26 | batch: 2] loss: 498.126\n",
      "[epoch: 26 | batch: 3] loss: 459.718\n",
      "[epoch: 26 | batch: 4] loss: 687.639\n",
      "[epoch: 26 | batch: 5] loss: 532.978\n",
      "[epoch: 26 | batch: 6] loss: 634.827\n",
      "[epoch: 26 | batch: 7] loss: 579.172\n",
      "[epoch: 26 | batch: 8] loss: 470.062\n",
      "[epoch: 26 | batch: 9] loss: 445.168\n",
      "[epoch: 26 | batch: 10] loss: 575.446\n",
      "[epoch: 26 | batch: 11] loss: 500.858\n",
      "[epoch: 26 | batch: 12] loss: 499.737\n",
      "[epoch: 26 | batch: 13] loss: 266.572\n",
      "mean epoch loss: 513.27\n",
      "saved model to ./model/colnet181105-21-31-14.pt\n",
      "End of epoch 26\n",
      "\n",
      "[epoch: 27 | batch: 1] loss: 522.278\n",
      "[epoch: 27 | batch: 2] loss: 493.887\n",
      "[epoch: 27 | batch: 3] loss: 462.206\n",
      "[epoch: 27 | batch: 4] loss: 691.207\n",
      "[epoch: 27 | batch: 5] loss: 533.885\n",
      "[epoch: 27 | batch: 6] loss: 634.763\n",
      "[epoch: 27 | batch: 7] loss: 577.092\n",
      "[epoch: 27 | batch: 8] loss: 473.759\n",
      "[epoch: 27 | batch: 9] loss: 446.460\n",
      "[epoch: 27 | batch: 10] loss: 572.510\n",
      "[epoch: 27 | batch: 11] loss: 506.220\n",
      "[epoch: 27 | batch: 12] loss: 496.204\n",
      "[epoch: 27 | batch: 13] loss: 260.891\n",
      "mean epoch loss: 513.18\n",
      "saved model to ./model/colnet181105-21-31-18.pt\n",
      "End of epoch 27\n",
      "\n",
      "[epoch: 28 | batch: 1] loss: 515.995\n",
      "[epoch: 28 | batch: 2] loss: 498.955\n",
      "[epoch: 28 | batch: 3] loss: 457.193\n",
      "[epoch: 28 | batch: 4] loss: 677.469\n",
      "[epoch: 28 | batch: 5] loss: 521.475\n",
      "[epoch: 28 | batch: 6] loss: 633.091\n",
      "[epoch: 28 | batch: 7] loss: 577.346\n",
      "[epoch: 28 | batch: 8] loss: 461.391\n",
      "[epoch: 28 | batch: 9] loss: 442.984\n",
      "[epoch: 28 | batch: 10] loss: 577.942\n",
      "[epoch: 28 | batch: 11] loss: 489.973\n",
      "[epoch: 28 | batch: 12] loss: 488.138\n",
      "[epoch: 28 | batch: 13] loss: 305.284\n",
      "mean epoch loss: 511.33\n",
      "saved model to ./model/colnet181105-21-31-22.pt\n",
      "End of epoch 28\n",
      "\n",
      "[epoch: 29 | batch: 1] loss: 507.298\n",
      "[epoch: 29 | batch: 2] loss: 476.362\n",
      "[epoch: 29 | batch: 3] loss: 471.057\n",
      "[epoch: 29 | batch: 4] loss: 707.517\n",
      "[epoch: 29 | batch: 5] loss: 550.605\n",
      "[epoch: 29 | batch: 6] loss: 635.649\n",
      "[epoch: 29 | batch: 7] loss: 573.041\n",
      "[epoch: 29 | batch: 8] loss: 493.188\n",
      "[epoch: 29 | batch: 9] loss: 449.602\n",
      "[epoch: 29 | batch: 10] loss: 566.826\n",
      "[epoch: 29 | batch: 11] loss: 523.551\n",
      "[epoch: 29 | batch: 12] loss: 494.728\n",
      "[epoch: 29 | batch: 13] loss: 264.739\n",
      "mean epoch loss: 516.47\n",
      "saved model to ./model/colnet181105-21-31-26.pt\n",
      "End of epoch 29\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 30 | batch: 1] loss: 504.025\n",
      "[epoch: 30 | batch: 2] loss: 493.868\n",
      "[epoch: 30 | batch: 3] loss: 456.323\n",
      "[epoch: 30 | batch: 4] loss: 681.360\n",
      "[epoch: 30 | batch: 5] loss: 536.167\n",
      "[epoch: 30 | batch: 6] loss: 634.113\n",
      "[epoch: 30 | batch: 7] loss: 579.640\n",
      "[epoch: 30 | batch: 8] loss: 468.937\n",
      "[epoch: 30 | batch: 9] loss: 443.544\n",
      "[epoch: 30 | batch: 10] loss: 573.968\n",
      "[epoch: 30 | batch: 11] loss: 535.609\n",
      "[epoch: 30 | batch: 12] loss: 497.225\n",
      "[epoch: 30 | batch: 13] loss: 249.779\n",
      "mean epoch loss: 511.89\n",
      "saved model to ./model/colnet181105-21-31-30.pt\n",
      "End of epoch 30\n",
      "\n",
      "[epoch: 31 | batch: 1] loss: 497.115\n",
      "[epoch: 31 | batch: 2] loss: 473.210\n",
      "[epoch: 31 | batch: 3] loss: 479.095\n",
      "[epoch: 31 | batch: 4] loss: 700.843\n",
      "[epoch: 31 | batch: 5] loss: 524.335\n",
      "[epoch: 31 | batch: 6] loss: 634.755\n",
      "[epoch: 31 | batch: 7] loss: 568.912\n",
      "[epoch: 31 | batch: 8] loss: 482.210\n",
      "[epoch: 31 | batch: 9] loss: 440.949\n",
      "[epoch: 31 | batch: 10] loss: 572.082\n",
      "[epoch: 31 | batch: 11] loss: 511.023\n",
      "[epoch: 31 | batch: 12] loss: 498.969\n",
      "[epoch: 31 | batch: 13] loss: 258.889\n",
      "mean epoch loss: 510.95\n",
      "saved model to ./model/colnet181105-21-31-34.pt\n",
      "End of epoch 31\n",
      "\n",
      "[epoch: 32 | batch: 1] loss: 509.975\n",
      "[epoch: 32 | batch: 2] loss: 490.038\n",
      "[epoch: 32 | batch: 3] loss: 462.609\n",
      "[epoch: 32 | batch: 4] loss: 685.164\n",
      "[epoch: 32 | batch: 5] loss: 523.439\n",
      "[epoch: 32 | batch: 6] loss: 635.458\n",
      "[epoch: 32 | batch: 7] loss: 579.602\n",
      "[epoch: 32 | batch: 8] loss: 466.210\n",
      "[epoch: 32 | batch: 9] loss: 441.589\n",
      "[epoch: 32 | batch: 10] loss: 577.194\n",
      "[epoch: 32 | batch: 11] loss: 502.488\n",
      "[epoch: 32 | batch: 12] loss: 501.215\n",
      "[epoch: 32 | batch: 13] loss: 258.167\n",
      "mean epoch loss: 510.24\n",
      "saved model to ./model/colnet181105-21-31-38.pt\n",
      "End of epoch 32\n",
      "\n",
      "[epoch: 33 | batch: 1] loss: 516.220\n",
      "[epoch: 33 | batch: 2] loss: 494.864\n",
      "[epoch: 33 | batch: 3] loss: 459.688\n",
      "[epoch: 33 | batch: 4] loss: 678.296\n",
      "[epoch: 33 | batch: 5] loss: 511.884\n",
      "[epoch: 33 | batch: 6] loss: 634.403\n",
      "[epoch: 33 | batch: 7] loss: 577.421\n",
      "[epoch: 33 | batch: 8] loss: 461.038\n",
      "[epoch: 33 | batch: 9] loss: 439.489\n",
      "[epoch: 33 | batch: 10] loss: 577.872\n",
      "[epoch: 33 | batch: 11] loss: 495.152\n",
      "[epoch: 33 | batch: 12] loss: 498.786\n",
      "[epoch: 33 | batch: 13] loss: 255.511\n",
      "mean epoch loss: 507.74\n",
      "saved model to ./model/colnet181105-21-31-42.pt\n",
      "End of epoch 33\n",
      "\n",
      "[epoch: 34 | batch: 1] loss: 516.861\n",
      "[epoch: 34 | batch: 2] loss: 496.810\n",
      "[epoch: 34 | batch: 3] loss: 458.841\n",
      "[epoch: 34 | batch: 4] loss: 673.589\n",
      "[epoch: 34 | batch: 5] loss: 507.300\n",
      "[epoch: 34 | batch: 6] loss: 633.446\n",
      "[epoch: 34 | batch: 7] loss: 575.932\n",
      "[epoch: 34 | batch: 8] loss: 457.546\n",
      "[epoch: 34 | batch: 9] loss: 439.191\n",
      "[epoch: 34 | batch: 10] loss: 576.228\n",
      "[epoch: 34 | batch: 11] loss: 490.882\n",
      "[epoch: 34 | batch: 12] loss: 495.020\n",
      "[epoch: 34 | batch: 13] loss: 254.175\n",
      "mean epoch loss: 505.83\n",
      "saved model to ./model/colnet181105-21-31-46.pt\n",
      "End of epoch 34\n",
      "\n",
      "[epoch: 35 | batch: 1] loss: 513.980\n",
      "[epoch: 35 | batch: 2] loss: 496.849\n",
      "[epoch: 35 | batch: 3] loss: 454.941\n",
      "[epoch: 35 | batch: 4] loss: 671.003\n",
      "[epoch: 35 | batch: 5] loss: 503.589\n",
      "[epoch: 35 | batch: 6] loss: 629.935\n",
      "[epoch: 35 | batch: 7] loss: 573.955\n",
      "[epoch: 35 | batch: 8] loss: 449.733\n",
      "[epoch: 35 | batch: 9] loss: 438.056\n",
      "[epoch: 35 | batch: 10] loss: 570.402\n",
      "[epoch: 35 | batch: 11] loss: 496.530\n",
      "[epoch: 35 | batch: 12] loss: 489.678\n",
      "[epoch: 35 | batch: 13] loss: 255.499\n",
      "mean epoch loss: 503.40\n",
      "saved model to ./model/colnet181105-21-31-51.pt\n",
      "End of epoch 35\n",
      "\n",
      "[epoch: 36 | batch: 1] loss: 503.988\n",
      "[epoch: 36 | batch: 2] loss: 478.009\n",
      "[epoch: 36 | batch: 3] loss: 471.407\n",
      "[epoch: 36 | batch: 4] loss: 692.971\n",
      "[epoch: 36 | batch: 5] loss: 511.040\n",
      "[epoch: 36 | batch: 6] loss: 630.453\n",
      "[epoch: 36 | batch: 7] loss: 569.127\n",
      "[epoch: 36 | batch: 8] loss: 462.625\n",
      "[epoch: 36 | batch: 9] loss: 434.879\n",
      "[epoch: 36 | batch: 10] loss: 567.055\n",
      "[epoch: 36 | batch: 11] loss: 495.528\n",
      "[epoch: 36 | batch: 12] loss: 485.511\n",
      "[epoch: 36 | batch: 13] loss: 280.507\n",
      "mean epoch loss: 506.39\n",
      "saved model to ./model/colnet181105-21-31-55.pt\n",
      "End of epoch 36\n",
      "\n",
      "[epoch: 37 | batch: 1] loss: 504.223\n",
      "[epoch: 37 | batch: 2] loss: 481.493\n",
      "[epoch: 37 | batch: 3] loss: 460.874\n",
      "[epoch: 37 | batch: 4] loss: 690.637\n",
      "[epoch: 37 | batch: 5] loss: 529.830\n",
      "[epoch: 37 | batch: 6] loss: 631.598\n",
      "[epoch: 37 | batch: 7] loss: 578.829\n",
      "[epoch: 37 | batch: 8] loss: 465.693\n",
      "[epoch: 37 | batch: 9] loss: 442.979\n",
      "[epoch: 37 | batch: 10] loss: 568.134\n",
      "[epoch: 37 | batch: 11] loss: 506.219\n",
      "[epoch: 37 | batch: 12] loss: 489.299\n",
      "[epoch: 37 | batch: 13] loss: 257.634\n",
      "mean epoch loss: 508.26\n",
      "saved model to ./model/colnet181105-21-31-59.pt\n",
      "End of epoch 37\n",
      "\n",
      "[epoch: 38 | batch: 1] loss: 505.592\n",
      "[epoch: 38 | batch: 2] loss: 500.458\n",
      "[epoch: 38 | batch: 3] loss: 451.026\n",
      "[epoch: 38 | batch: 4] loss: 656.929\n",
      "[epoch: 38 | batch: 5] loss: 509.689\n",
      "[epoch: 38 | batch: 6] loss: 630.419\n",
      "[epoch: 38 | batch: 7] loss: 579.362\n",
      "[epoch: 38 | batch: 8] loss: 453.420\n",
      "[epoch: 38 | batch: 9] loss: 444.991\n",
      "[epoch: 38 | batch: 10] loss: 581.954\n",
      "[epoch: 38 | batch: 11] loss: 488.106\n",
      "[epoch: 38 | batch: 12] loss: 489.635\n",
      "[epoch: 38 | batch: 13] loss: 248.898\n",
      "mean epoch loss: 503.11\n",
      "saved model to ./model/colnet181105-21-32-03.pt\n",
      "End of epoch 38\n",
      "\n",
      "[epoch: 39 | batch: 1] loss: 505.666\n",
      "[epoch: 39 | batch: 2] loss: 498.139\n",
      "[epoch: 39 | batch: 3] loss: 450.712\n",
      "[epoch: 39 | batch: 4] loss: 655.767\n",
      "[epoch: 39 | batch: 5] loss: 491.531\n",
      "[epoch: 39 | batch: 6] loss: 627.994\n",
      "[epoch: 39 | batch: 7] loss: 571.599\n",
      "[epoch: 39 | batch: 8] loss: 449.194\n",
      "[epoch: 39 | batch: 9] loss: 435.302\n",
      "[epoch: 39 | batch: 10] loss: 581.404\n",
      "[epoch: 39 | batch: 11] loss: 476.154\n",
      "[epoch: 39 | batch: 12] loss: 492.130\n",
      "[epoch: 39 | batch: 13] loss: 271.438\n",
      "mean epoch loss: 500.54\n",
      "saved model to ./model/colnet181105-21-32-07.pt\n",
      "End of epoch 39\n",
      "\n",
      "[epoch: 40 | batch: 1] loss: 505.611\n",
      "[epoch: 40 | batch: 2] loss: 479.294\n",
      "[epoch: 40 | batch: 3] loss: 464.834\n",
      "[epoch: 40 | batch: 4] loss: 683.652\n",
      "[epoch: 40 | batch: 5] loss: 502.616\n",
      "[epoch: 40 | batch: 6] loss: 627.922\n",
      "[epoch: 40 | batch: 7] loss: 570.458\n",
      "[epoch: 40 | batch: 8] loss: 462.413\n",
      "[epoch: 40 | batch: 9] loss: 434.174\n",
      "[epoch: 40 | batch: 10] loss: 567.216\n",
      "[epoch: 40 | batch: 11] loss: 495.377\n",
      "[epoch: 40 | batch: 12] loss: 490.507\n",
      "[epoch: 40 | batch: 13] loss: 250.153\n",
      "mean epoch loss: 502.63\n",
      "saved model to ./model/colnet181105-21-32-11.pt\n",
      "End of epoch 40\n",
      "\n",
      "[epoch: 41 | batch: 1] loss: 504.609\n",
      "[epoch: 41 | batch: 2] loss: 491.972\n",
      "[epoch: 41 | batch: 3] loss: 450.635\n",
      "[epoch: 41 | batch: 4] loss: 665.521\n",
      "[epoch: 41 | batch: 5] loss: 489.416\n",
      "[epoch: 41 | batch: 6] loss: 627.280\n",
      "[epoch: 41 | batch: 7] loss: 577.266\n",
      "[epoch: 41 | batch: 8] loss: 444.780\n",
      "[epoch: 41 | batch: 9] loss: 432.895\n",
      "[epoch: 41 | batch: 10] loss: 578.806\n",
      "[epoch: 41 | batch: 11] loss: 477.123\n",
      "[epoch: 41 | batch: 12] loss: 496.042\n",
      "[epoch: 41 | batch: 13] loss: 247.707\n",
      "mean epoch loss: 498.77\n",
      "saved model to ./model/colnet181105-21-32-15.pt\n",
      "End of epoch 41\n",
      "\n",
      "[epoch: 42 | batch: 1] loss: 509.686\n",
      "[epoch: 42 | batch: 2] loss: 496.484\n",
      "[epoch: 42 | batch: 3] loss: 452.891\n",
      "[epoch: 42 | batch: 4] loss: 663.728\n",
      "[epoch: 42 | batch: 5] loss: 482.046\n",
      "[epoch: 42 | batch: 6] loss: 622.884\n",
      "[epoch: 42 | batch: 7] loss: 570.287\n",
      "[epoch: 42 | batch: 8] loss: 449.081\n",
      "[epoch: 42 | batch: 9] loss: 426.633\n",
      "[epoch: 42 | batch: 10] loss: 564.848\n",
      "[epoch: 42 | batch: 11] loss: 479.108\n",
      "[epoch: 42 | batch: 12] loss: 484.476\n",
      "[epoch: 42 | batch: 13] loss: 253.296\n",
      "mean epoch loss: 496.57\n",
      "saved model to ./model/colnet181105-21-32-19.pt\n",
      "End of epoch 42\n",
      "\n",
      "[epoch: 43 | batch: 1] loss: 504.302\n",
      "[epoch: 43 | batch: 2] loss: 483.332\n",
      "[epoch: 43 | batch: 3] loss: 457.595\n",
      "[epoch: 43 | batch: 4] loss: 689.012\n",
      "[epoch: 43 | batch: 5] loss: 480.123\n",
      "[epoch: 43 | batch: 6] loss: 618.417\n",
      "[epoch: 43 | batch: 7] loss: 573.152\n",
      "[epoch: 43 | batch: 8] loss: 449.337\n",
      "[epoch: 43 | batch: 9] loss: 421.833\n",
      "[epoch: 43 | batch: 10] loss: 561.352\n",
      "[epoch: 43 | batch: 11] loss: 476.516\n",
      "[epoch: 43 | batch: 12] loss: 492.251\n",
      "[epoch: 43 | batch: 13] loss: 250.395\n",
      "mean epoch loss: 496.74\n",
      "saved model to ./model/colnet181105-21-32-23.pt\n",
      "End of epoch 43\n",
      "\n",
      "[epoch: 44 | batch: 1] loss: 508.942\n",
      "[epoch: 44 | batch: 2] loss: 493.825\n",
      "[epoch: 44 | batch: 3] loss: 446.301\n",
      "[epoch: 44 | batch: 4] loss: 674.623\n",
      "[epoch: 44 | batch: 5] loss: 477.190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 44 | batch: 6] loss: 617.993\n",
      "[epoch: 44 | batch: 7] loss: 578.615\n",
      "[epoch: 44 | batch: 8] loss: 440.489\n",
      "[epoch: 44 | batch: 9] loss: 419.026\n",
      "[epoch: 44 | batch: 10] loss: 559.169\n",
      "[epoch: 44 | batch: 11] loss: 461.076\n",
      "[epoch: 44 | batch: 12] loss: 481.874\n",
      "[epoch: 44 | batch: 13] loss: 271.682\n",
      "mean epoch loss: 494.68\n",
      "saved model to ./model/colnet181105-21-32-27.pt\n",
      "End of epoch 44\n",
      "\n",
      "[epoch: 45 | batch: 1] loss: 498.998\n",
      "[epoch: 45 | batch: 2] loss: 480.350\n",
      "[epoch: 45 | batch: 3] loss: 450.229\n",
      "[epoch: 45 | batch: 4] loss: 696.608\n",
      "[epoch: 45 | batch: 5] loss: 495.188\n",
      "[epoch: 45 | batch: 6] loss: 619.853\n",
      "[epoch: 45 | batch: 7] loss: 581.773\n",
      "[epoch: 45 | batch: 8] loss: 460.142\n",
      "[epoch: 45 | batch: 9] loss: 421.735\n",
      "[epoch: 45 | batch: 10] loss: 552.916\n",
      "[epoch: 45 | batch: 11] loss: 492.331\n",
      "[epoch: 45 | batch: 12] loss: 487.125\n",
      "[epoch: 45 | batch: 13] loss: 248.836\n",
      "mean epoch loss: 498.93\n",
      "saved model to ./model/colnet181105-21-32-31.pt\n",
      "End of epoch 45\n",
      "\n",
      "[epoch: 46 | batch: 1] loss: 508.909\n",
      "[epoch: 46 | batch: 2] loss: 504.078\n",
      "[epoch: 46 | batch: 3] loss: 433.145\n",
      "[epoch: 46 | batch: 4] loss: 655.311\n",
      "[epoch: 46 | batch: 5] loss: 464.682\n",
      "[epoch: 46 | batch: 6] loss: 613.204\n",
      "[epoch: 46 | batch: 7] loss: 584.456\n",
      "[epoch: 46 | batch: 8] loss: 439.970\n",
      "[epoch: 46 | batch: 9] loss: 417.889\n",
      "[epoch: 46 | batch: 10] loss: 569.234\n",
      "[epoch: 46 | batch: 11] loss: 455.752\n",
      "[epoch: 46 | batch: 12] loss: 491.865\n",
      "[epoch: 46 | batch: 13] loss: 249.729\n",
      "mean epoch loss: 491.40\n",
      "saved model to ./model/colnet181105-21-32-35.pt\n",
      "End of epoch 46\n",
      "\n",
      "[epoch: 47 | batch: 1] loss: 510.690\n",
      "[epoch: 47 | batch: 2] loss: 503.422\n",
      "[epoch: 47 | batch: 3] loss: 433.736\n",
      "[epoch: 47 | batch: 4] loss: 675.896\n",
      "[epoch: 47 | batch: 5] loss: 456.955\n",
      "[epoch: 47 | batch: 6] loss: 617.306\n",
      "[epoch: 47 | batch: 7] loss: 584.229\n",
      "[epoch: 47 | batch: 8] loss: 443.679\n",
      "[epoch: 47 | batch: 9] loss: 407.652\n",
      "[epoch: 47 | batch: 10] loss: 556.161\n",
      "[epoch: 47 | batch: 11] loss: 450.040\n",
      "[epoch: 47 | batch: 12] loss: 487.037\n",
      "[epoch: 47 | batch: 13] loss: 245.362\n",
      "mean epoch loss: 490.17\n",
      "saved model to ./model/colnet181105-21-32-39.pt\n",
      "End of epoch 47\n",
      "\n",
      "[epoch: 48 | batch: 1] loss: 501.442\n",
      "[epoch: 48 | batch: 2] loss: 502.164\n",
      "[epoch: 48 | batch: 3] loss: 433.295\n",
      "[epoch: 48 | batch: 4] loss: 675.328\n",
      "[epoch: 48 | batch: 5] loss: 439.323\n",
      "[epoch: 48 | batch: 6] loss: 610.011\n",
      "[epoch: 48 | batch: 7] loss: 587.265\n",
      "[epoch: 48 | batch: 8] loss: 435.126\n",
      "[epoch: 48 | batch: 9] loss: 409.194\n",
      "[epoch: 48 | batch: 10] loss: 554.381\n",
      "[epoch: 48 | batch: 11] loss: 435.383\n",
      "[epoch: 48 | batch: 12] loss: 484.572\n",
      "[epoch: 48 | batch: 13] loss: 293.045\n",
      "mean epoch loss: 489.27\n",
      "saved model to ./model/colnet181105-21-32-43.pt\n",
      "End of epoch 48\n",
      "\n",
      "[epoch: 49 | batch: 1] loss: 488.865\n",
      "[epoch: 49 | batch: 2] loss: 480.094\n",
      "[epoch: 49 | batch: 3] loss: 439.224\n",
      "[epoch: 49 | batch: 4] loss: 709.335\n",
      "[epoch: 49 | batch: 5] loss: 459.119\n",
      "[epoch: 49 | batch: 6] loss: 624.099\n",
      "[epoch: 49 | batch: 7] loss: 586.422\n",
      "[epoch: 49 | batch: 8] loss: 444.085\n",
      "[epoch: 49 | batch: 9] loss: 404.366\n",
      "[epoch: 49 | batch: 10] loss: 546.458\n",
      "[epoch: 49 | batch: 11] loss: 464.374\n",
      "[epoch: 49 | batch: 12] loss: 493.423\n",
      "[epoch: 49 | batch: 13] loss: 244.846\n",
      "mean epoch loss: 491.13\n",
      "saved model to ./model/colnet181105-21-32-47.pt\n",
      "End of epoch 49\n",
      "\n",
      "[epoch: 50 | batch: 1] loss: 501.580\n",
      "[epoch: 50 | batch: 2] loss: 501.974\n",
      "[epoch: 50 | batch: 3] loss: 427.174\n",
      "[epoch: 50 | batch: 4] loss: 662.934\n",
      "[epoch: 50 | batch: 5] loss: 447.329\n",
      "[epoch: 50 | batch: 6] loss: 611.143\n",
      "[epoch: 50 | batch: 7] loss: 587.788\n",
      "[epoch: 50 | batch: 8] loss: 442.441\n",
      "[epoch: 50 | batch: 9] loss: 407.530\n",
      "[epoch: 50 | batch: 10] loss: 557.721\n",
      "[epoch: 50 | batch: 11] loss: 432.280\n",
      "[epoch: 50 | batch: 12] loss: 487.883\n",
      "[epoch: 50 | batch: 13] loss: 234.257\n",
      "mean epoch loss: 484.77\n",
      "saved model to ./model/colnet181105-21-32-51.pt\n",
      "End of epoch 50\n",
      "\n",
      "[epoch: 51 | batch: 1] loss: 499.314\n",
      "[epoch: 51 | batch: 2] loss: 501.506\n",
      "[epoch: 51 | batch: 3] loss: 422.578\n",
      "[epoch: 51 | batch: 4] loss: 675.450\n",
      "[epoch: 51 | batch: 5] loss: 427.057\n",
      "[epoch: 51 | batch: 6] loss: 610.432\n",
      "[epoch: 51 | batch: 7] loss: 590.681\n",
      "[epoch: 51 | batch: 8] loss: 433.316\n",
      "[epoch: 51 | batch: 9] loss: 412.651\n",
      "[epoch: 51 | batch: 10] loss: 555.487\n",
      "[epoch: 51 | batch: 11] loss: 418.650\n",
      "[epoch: 51 | batch: 12] loss: 486.812\n",
      "[epoch: 51 | batch: 13] loss: 221.976\n",
      "mean epoch loss: 481.22\n",
      "saved model to ./model/colnet181105-21-32-56.pt\n",
      "End of epoch 51\n",
      "\n",
      "[epoch: 52 | batch: 1] loss: 481.788\n",
      "[epoch: 52 | batch: 2] loss: 491.925\n",
      "[epoch: 52 | batch: 3] loss: 422.641\n",
      "[epoch: 52 | batch: 4] loss: 681.736\n",
      "[epoch: 52 | batch: 5] loss: 428.676\n",
      "[epoch: 52 | batch: 6] loss: 603.992\n",
      "[epoch: 52 | batch: 7] loss: 589.062\n",
      "[epoch: 52 | batch: 8] loss: 441.013\n",
      "[epoch: 52 | batch: 9] loss: 417.262\n",
      "[epoch: 52 | batch: 10] loss: 548.937\n",
      "[epoch: 52 | batch: 11] loss: 423.434\n",
      "[epoch: 52 | batch: 12] loss: 476.889\n",
      "[epoch: 52 | batch: 13] loss: 209.971\n",
      "mean epoch loss: 478.26\n",
      "saved model to ./model/colnet181105-21-33-00.pt\n",
      "End of epoch 52\n",
      "\n",
      "[epoch: 53 | batch: 1] loss: 466.563\n",
      "[epoch: 53 | batch: 2] loss: 474.075\n",
      "[epoch: 53 | batch: 3] loss: 432.120\n",
      "[epoch: 53 | batch: 4] loss: 691.938\n",
      "[epoch: 53 | batch: 5] loss: 423.962\n",
      "[epoch: 53 | batch: 6] loss: 583.611\n",
      "[epoch: 53 | batch: 7] loss: 582.570\n",
      "[epoch: 53 | batch: 8] loss: 438.706\n",
      "[epoch: 53 | batch: 9] loss: 423.207\n",
      "[epoch: 53 | batch: 10] loss: 550.357\n",
      "[epoch: 53 | batch: 11] loss: 428.988\n",
      "[epoch: 53 | batch: 12] loss: 470.459\n",
      "[epoch: 53 | batch: 13] loss: 200.857\n",
      "mean epoch loss: 474.42\n",
      "saved model to ./model/colnet181105-21-33-04.pt\n",
      "End of epoch 53\n",
      "\n",
      "[epoch: 54 | batch: 1] loss: 450.088\n",
      "[epoch: 54 | batch: 2] loss: 474.622\n",
      "[epoch: 54 | batch: 3] loss: 425.450\n",
      "[epoch: 54 | batch: 4] loss: 698.386\n",
      "[epoch: 54 | batch: 5] loss: 443.123\n",
      "[epoch: 54 | batch: 6] loss: 589.204\n",
      "[epoch: 54 | batch: 7] loss: 582.010\n",
      "[epoch: 54 | batch: 8] loss: 439.967\n",
      "[epoch: 54 | batch: 9] loss: 412.149\n",
      "[epoch: 54 | batch: 10] loss: 541.119\n",
      "[epoch: 54 | batch: 11] loss: 448.290\n",
      "[epoch: 54 | batch: 12] loss: 474.062\n",
      "[epoch: 54 | batch: 13] loss: 206.815\n",
      "mean epoch loss: 475.79\n",
      "saved model to ./model/colnet181105-21-33-08.pt\n",
      "End of epoch 54\n",
      "\n",
      "[epoch: 55 | batch: 1] loss: 450.761\n",
      "[epoch: 55 | batch: 2] loss: 470.301\n",
      "[epoch: 55 | batch: 3] loss: 424.696\n",
      "[epoch: 55 | batch: 4] loss: 692.604\n",
      "[epoch: 55 | batch: 5] loss: 441.507\n",
      "[epoch: 55 | batch: 6] loss: 583.771\n",
      "[epoch: 55 | batch: 7] loss: 587.165\n",
      "[epoch: 55 | batch: 8] loss: 439.875\n",
      "[epoch: 55 | batch: 9] loss: 414.498\n",
      "[epoch: 55 | batch: 10] loss: 535.191\n",
      "[epoch: 55 | batch: 11] loss: 439.222\n",
      "[epoch: 55 | batch: 12] loss: 462.952\n",
      "[epoch: 55 | batch: 13] loss: 208.119\n",
      "mean epoch loss: 473.13\n",
      "saved model to ./model/colnet181105-21-33-12.pt\n",
      "End of epoch 55\n",
      "\n",
      "[epoch: 56 | batch: 1] loss: 460.253\n",
      "[epoch: 56 | batch: 2] loss: 483.442\n",
      "[epoch: 56 | batch: 3] loss: 414.900\n",
      "[epoch: 56 | batch: 4] loss: 671.546\n",
      "[epoch: 56 | batch: 5] loss: 411.729\n",
      "[epoch: 56 | batch: 6] loss: 570.709\n",
      "[epoch: 56 | batch: 7] loss: 575.408\n",
      "[epoch: 56 | batch: 8] loss: 425.121\n",
      "[epoch: 56 | batch: 9] loss: 411.186\n",
      "[epoch: 56 | batch: 10] loss: 550.757\n",
      "[epoch: 56 | batch: 11] loss: 410.001\n",
      "[epoch: 56 | batch: 12] loss: 463.509\n",
      "[epoch: 56 | batch: 13] loss: 188.603\n",
      "mean epoch loss: 464.40\n",
      "saved model to ./model/colnet181105-21-33-16.pt\n",
      "End of epoch 56\n",
      "\n",
      "[epoch: 57 | batch: 1] loss: 433.982\n",
      "[epoch: 57 | batch: 2] loss: 466.767\n",
      "[epoch: 57 | batch: 3] loss: 419.495\n",
      "[epoch: 57 | batch: 4] loss: 686.771\n",
      "[epoch: 57 | batch: 5] loss: 425.353\n",
      "[epoch: 57 | batch: 6] loss: 569.046\n",
      "[epoch: 57 | batch: 7] loss: 563.399\n",
      "[epoch: 57 | batch: 8] loss: 434.332\n",
      "[epoch: 57 | batch: 9] loss: 407.053\n",
      "[epoch: 57 | batch: 10] loss: 530.009\n",
      "[epoch: 57 | batch: 11] loss: 433.245\n",
      "[epoch: 57 | batch: 12] loss: 456.807\n",
      "[epoch: 57 | batch: 13] loss: 198.060\n",
      "mean epoch loss: 463.41\n",
      "saved model to ./model/colnet181105-21-33-20.pt\n",
      "End of epoch 57\n",
      "\n",
      "[epoch: 58 | batch: 1] loss: 431.360\n",
      "[epoch: 58 | batch: 2] loss: 458.994\n",
      "[epoch: 58 | batch: 3] loss: 429.439\n",
      "[epoch: 58 | batch: 4] loss: 670.842\n",
      "[epoch: 58 | batch: 5] loss: 441.178\n",
      "[epoch: 58 | batch: 6] loss: 550.610\n",
      "[epoch: 58 | batch: 7] loss: 550.670\n",
      "[epoch: 58 | batch: 8] loss: 424.966\n",
      "[epoch: 58 | batch: 9] loss: 393.321\n",
      "[epoch: 58 | batch: 10] loss: 534.976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 58 | batch: 11] loss: 443.754\n",
      "[epoch: 58 | batch: 12] loss: 466.247\n",
      "[epoch: 58 | batch: 13] loss: 197.211\n",
      "mean epoch loss: 461.04\n",
      "saved model to ./model/colnet181105-21-33-24.pt\n",
      "End of epoch 58\n",
      "\n",
      "[epoch: 59 | batch: 1] loss: 434.005\n",
      "[epoch: 59 | batch: 2] loss: 452.095\n",
      "[epoch: 59 | batch: 3] loss: 420.234\n",
      "[epoch: 59 | batch: 4] loss: 671.390\n",
      "[epoch: 59 | batch: 5] loss: 435.202\n",
      "[epoch: 59 | batch: 6] loss: 555.899\n",
      "[epoch: 59 | batch: 7] loss: 572.346\n",
      "[epoch: 59 | batch: 8] loss: 430.602\n",
      "[epoch: 59 | batch: 9] loss: 404.581\n",
      "[epoch: 59 | batch: 10] loss: 524.195\n",
      "[epoch: 59 | batch: 11] loss: 435.504\n",
      "[epoch: 59 | batch: 12] loss: 457.227\n",
      "[epoch: 59 | batch: 13] loss: 199.934\n",
      "mean epoch loss: 461.02\n",
      "saved model to ./model/colnet181105-21-33-29.pt\n",
      "End of epoch 59\n",
      "\n",
      "[epoch: 60 | batch: 1] loss: 451.165\n",
      "[epoch: 60 | batch: 2] loss: 478.261\n",
      "[epoch: 60 | batch: 3] loss: 413.139\n",
      "[epoch: 60 | batch: 4] loss: 672.707\n",
      "[epoch: 60 | batch: 5] loss: 402.909\n",
      "[epoch: 60 | batch: 6] loss: 548.575\n",
      "[epoch: 60 | batch: 7] loss: 557.544\n",
      "[epoch: 60 | batch: 8] loss: 417.200\n",
      "[epoch: 60 | batch: 9] loss: 415.767\n",
      "[epoch: 60 | batch: 10] loss: 536.339\n",
      "[epoch: 60 | batch: 11] loss: 418.780\n",
      "[epoch: 60 | batch: 12] loss: 452.083\n",
      "[epoch: 60 | batch: 13] loss: 189.311\n",
      "mean epoch loss: 457.98\n",
      "saved model to ./model/colnet181105-21-33-33.pt\n",
      "End of epoch 60\n",
      "\n",
      "[epoch: 61 | batch: 1] loss: 431.363\n",
      "[epoch: 61 | batch: 2] loss: 458.955\n",
      "[epoch: 61 | batch: 3] loss: 416.348\n",
      "[epoch: 61 | batch: 4] loss: 677.842\n",
      "[epoch: 61 | batch: 5] loss: 406.224\n",
      "[epoch: 61 | batch: 6] loss: 545.545\n",
      "[epoch: 61 | batch: 7] loss: 541.242\n",
      "[epoch: 61 | batch: 8] loss: 418.355\n",
      "[epoch: 61 | batch: 9] loss: 410.169\n",
      "[epoch: 61 | batch: 10] loss: 524.206\n",
      "[epoch: 61 | batch: 11] loss: 433.057\n",
      "[epoch: 61 | batch: 12] loss: 447.615\n",
      "[epoch: 61 | batch: 13] loss: 192.773\n",
      "mean epoch loss: 454.13\n",
      "saved model to ./model/colnet181105-21-33-37.pt\n",
      "End of epoch 61\n",
      "\n",
      "[epoch: 62 | batch: 1] loss: 422.749\n",
      "[epoch: 62 | batch: 2] loss: 450.312\n",
      "[epoch: 62 | batch: 3] loss: 416.662\n",
      "[epoch: 62 | batch: 4] loss: 676.766\n",
      "[epoch: 62 | batch: 5] loss: 412.809\n",
      "[epoch: 62 | batch: 6] loss: 544.233\n",
      "[epoch: 62 | batch: 7] loss: 541.318\n",
      "[epoch: 62 | batch: 8] loss: 404.710\n",
      "[epoch: 62 | batch: 9] loss: 390.723\n",
      "[epoch: 62 | batch: 10] loss: 521.657\n",
      "[epoch: 62 | batch: 11] loss: 445.388\n",
      "[epoch: 62 | batch: 12] loss: 456.982\n",
      "[epoch: 62 | batch: 13] loss: 199.903\n",
      "mean epoch loss: 452.63\n",
      "saved model to ./model/colnet181105-21-33-41.pt\n",
      "End of epoch 62\n",
      "\n",
      "[epoch: 63 | batch: 1] loss: 416.350\n",
      "[epoch: 63 | batch: 2] loss: 442.205\n",
      "[epoch: 63 | batch: 3] loss: 415.373\n",
      "[epoch: 63 | batch: 4] loss: 667.098\n",
      "[epoch: 63 | batch: 5] loss: 425.232\n",
      "[epoch: 63 | batch: 6] loss: 544.723\n",
      "[epoch: 63 | batch: 7] loss: 549.505\n",
      "[epoch: 63 | batch: 8] loss: 410.353\n",
      "[epoch: 63 | batch: 9] loss: 387.682\n",
      "[epoch: 63 | batch: 10] loss: 509.773\n",
      "[epoch: 63 | batch: 11] loss: 441.351\n",
      "[epoch: 63 | batch: 12] loss: 450.355\n",
      "[epoch: 63 | batch: 13] loss: 204.629\n",
      "mean epoch loss: 451.13\n",
      "saved model to ./model/colnet181105-21-33-45.pt\n",
      "End of epoch 63\n",
      "\n",
      "[epoch: 64 | batch: 1] loss: 439.816\n",
      "[epoch: 64 | batch: 2] loss: 465.516\n",
      "[epoch: 64 | batch: 3] loss: 413.296\n",
      "[epoch: 64 | batch: 4] loss: 645.221\n",
      "[epoch: 64 | batch: 5] loss: 398.102\n",
      "[epoch: 64 | batch: 6] loss: 531.204\n",
      "[epoch: 64 | batch: 7] loss: 552.349\n",
      "[epoch: 64 | batch: 8] loss: 403.431\n",
      "[epoch: 64 | batch: 9] loss: 404.078\n",
      "[epoch: 64 | batch: 10] loss: 518.422\n",
      "[epoch: 64 | batch: 11] loss: 412.884\n",
      "[epoch: 64 | batch: 12] loss: 437.820\n",
      "[epoch: 64 | batch: 13] loss: 191.646\n",
      "mean epoch loss: 447.21\n",
      "saved model to ./model/colnet181105-21-33-49.pt\n",
      "End of epoch 64\n",
      "\n",
      "[epoch: 65 | batch: 1] loss: 426.804\n",
      "[epoch: 65 | batch: 2] loss: 461.827\n",
      "[epoch: 65 | batch: 3] loss: 406.145\n",
      "[epoch: 65 | batch: 4] loss: 639.144\n",
      "[epoch: 65 | batch: 5] loss: 388.839\n",
      "[epoch: 65 | batch: 6] loss: 517.980\n",
      "[epoch: 65 | batch: 7] loss: 534.411\n",
      "[epoch: 65 | batch: 8] loss: 396.392\n",
      "[epoch: 65 | batch: 9] loss: 396.755\n",
      "[epoch: 65 | batch: 10] loss: 514.847\n",
      "[epoch: 65 | batch: 11] loss: 402.229\n",
      "[epoch: 65 | batch: 12] loss: 443.401\n",
      "[epoch: 65 | batch: 13] loss: 177.900\n",
      "mean epoch loss: 438.98\n",
      "saved model to ./model/colnet181105-21-33-54.pt\n",
      "End of epoch 65\n",
      "\n",
      "[epoch: 66 | batch: 1] loss: 409.511\n",
      "[epoch: 66 | batch: 2] loss: 429.625\n",
      "[epoch: 66 | batch: 3] loss: 421.138\n",
      "[epoch: 66 | batch: 4] loss: 655.040\n",
      "[epoch: 66 | batch: 5] loss: 399.561\n",
      "[epoch: 66 | batch: 6] loss: 512.118\n",
      "[epoch: 66 | batch: 7] loss: 523.307\n",
      "[epoch: 66 | batch: 8] loss: 406.726\n",
      "[epoch: 66 | batch: 9] loss: 399.636\n",
      "[epoch: 66 | batch: 10] loss: 500.749\n",
      "[epoch: 66 | batch: 11] loss: 421.836\n",
      "[epoch: 66 | batch: 12] loss: 436.432\n",
      "[epoch: 66 | batch: 13] loss: 178.012\n",
      "mean epoch loss: 437.98\n",
      "saved model to ./model/colnet181105-21-33-58.pt\n",
      "End of epoch 66\n",
      "\n",
      "[epoch: 67 | batch: 1] loss: 412.556\n",
      "[epoch: 67 | batch: 2] loss: 441.905\n",
      "[epoch: 67 | batch: 3] loss: 420.058\n",
      "[epoch: 67 | batch: 4] loss: 663.965\n",
      "[epoch: 67 | batch: 5] loss: 391.224\n",
      "[epoch: 67 | batch: 6] loss: 497.768\n",
      "[epoch: 67 | batch: 7] loss: 525.548\n",
      "[epoch: 67 | batch: 8] loss: 398.253\n",
      "[epoch: 67 | batch: 9] loss: 388.062\n",
      "[epoch: 67 | batch: 10] loss: 508.462\n",
      "[epoch: 67 | batch: 11] loss: 432.888\n",
      "[epoch: 67 | batch: 12] loss: 443.190\n",
      "[epoch: 67 | batch: 13] loss: 183.598\n",
      "mean epoch loss: 439.04\n",
      "saved model to ./model/colnet181105-21-34-02.pt\n",
      "End of epoch 67\n",
      "\n",
      "[epoch: 68 | batch: 1] loss: 408.000\n",
      "[epoch: 68 | batch: 2] loss: 428.135\n",
      "[epoch: 68 | batch: 3] loss: 412.157\n",
      "[epoch: 68 | batch: 4] loss: 668.367\n",
      "[epoch: 68 | batch: 5] loss: 418.031\n",
      "[epoch: 68 | batch: 6] loss: 515.657\n",
      "[epoch: 68 | batch: 7] loss: 522.449\n",
      "[epoch: 68 | batch: 8] loss: 395.003\n",
      "[epoch: 68 | batch: 9] loss: 386.532\n",
      "[epoch: 68 | batch: 10] loss: 495.330\n",
      "[epoch: 68 | batch: 11] loss: 438.030\n",
      "[epoch: 68 | batch: 12] loss: 437.862\n",
      "[epoch: 68 | batch: 13] loss: 189.781\n",
      "mean epoch loss: 439.64\n",
      "saved model to ./model/colnet181105-21-34-06.pt\n",
      "End of epoch 68\n",
      "\n",
      "[epoch: 69 | batch: 1] loss: 410.453\n",
      "[epoch: 69 | batch: 2] loss: 435.541\n",
      "[epoch: 69 | batch: 3] loss: 414.303\n",
      "[epoch: 69 | batch: 4] loss: 673.886\n",
      "[epoch: 69 | batch: 5] loss: 401.016\n",
      "[epoch: 69 | batch: 6] loss: 517.805\n",
      "[epoch: 69 | batch: 7] loss: 528.794\n",
      "[epoch: 69 | batch: 8] loss: 390.462\n",
      "[epoch: 69 | batch: 9] loss: 389.444\n",
      "[epoch: 69 | batch: 10] loss: 496.092\n",
      "[epoch: 69 | batch: 11] loss: 437.901\n",
      "[epoch: 69 | batch: 12] loss: 438.892\n",
      "[epoch: 69 | batch: 13] loss: 194.954\n",
      "mean epoch loss: 440.73\n",
      "saved model to ./model/colnet181105-21-34-10.pt\n",
      "End of epoch 69\n",
      "\n",
      "[epoch: 70 | batch: 1] loss: 426.831\n",
      "[epoch: 70 | batch: 2] loss: 448.854\n",
      "[epoch: 70 | batch: 3] loss: 405.288\n",
      "[epoch: 70 | batch: 4] loss: 651.885\n",
      "[epoch: 70 | batch: 5] loss: 391.712\n",
      "[epoch: 70 | batch: 6] loss: 514.362\n",
      "[epoch: 70 | batch: 7] loss: 531.335\n",
      "[epoch: 70 | batch: 8] loss: 393.470\n",
      "[epoch: 70 | batch: 9] loss: 400.720\n",
      "[epoch: 70 | batch: 10] loss: 496.051\n",
      "[epoch: 70 | batch: 11] loss: 417.027\n",
      "[epoch: 70 | batch: 12] loss: 427.025\n",
      "[epoch: 70 | batch: 13] loss: 190.264\n",
      "mean epoch loss: 438.06\n",
      "saved model to ./model/colnet181105-21-34-15.pt\n",
      "End of epoch 70\n",
      "\n",
      "[epoch: 71 | batch: 1] loss: 411.386\n",
      "[epoch: 71 | batch: 2] loss: 437.103\n",
      "[epoch: 71 | batch: 3] loss: 402.062\n",
      "[epoch: 71 | batch: 4] loss: 641.796\n",
      "[epoch: 71 | batch: 5] loss: 390.694\n",
      "[epoch: 71 | batch: 6] loss: 515.234\n",
      "[epoch: 71 | batch: 7] loss: 520.699\n",
      "[epoch: 71 | batch: 8] loss: 379.583\n",
      "[epoch: 71 | batch: 9] loss: 391.192\n",
      "[epoch: 71 | batch: 10] loss: 502.701\n",
      "[epoch: 71 | batch: 11] loss: 413.635\n",
      "[epoch: 71 | batch: 12] loss: 425.264\n",
      "[epoch: 71 | batch: 13] loss: 180.452\n",
      "mean epoch loss: 431.68\n",
      "saved model to ./model/colnet181105-21-34-19.pt\n",
      "End of epoch 71\n",
      "\n",
      "[epoch: 72 | batch: 1] loss: 398.698\n",
      "[epoch: 72 | batch: 2] loss: 430.260\n",
      "[epoch: 72 | batch: 3] loss: 405.677\n",
      "[epoch: 72 | batch: 4] loss: 637.217\n",
      "[epoch: 72 | batch: 5] loss: 377.291\n",
      "[epoch: 72 | batch: 6] loss: 504.586\n",
      "[epoch: 72 | batch: 7] loss: 509.623\n",
      "[epoch: 72 | batch: 8] loss: 369.680\n",
      "[epoch: 72 | batch: 9] loss: 382.031\n",
      "[epoch: 72 | batch: 10] loss: 489.550\n",
      "[epoch: 72 | batch: 11] loss: 414.254\n",
      "[epoch: 72 | batch: 12] loss: 421.552\n",
      "[epoch: 72 | batch: 13] loss: 178.630\n",
      "mean epoch loss: 424.54\n",
      "saved model to ./model/colnet181105-21-34-23.pt\n",
      "End of epoch 72\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 73 | batch: 1] loss: 391.601\n",
      "[epoch: 73 | batch: 2] loss: 419.635\n",
      "[epoch: 73 | batch: 3] loss: 411.147\n",
      "[epoch: 73 | batch: 4] loss: 648.353\n",
      "[epoch: 73 | batch: 5] loss: 388.080\n",
      "[epoch: 73 | batch: 6] loss: 496.685\n",
      "[epoch: 73 | batch: 7] loss: 513.841\n",
      "[epoch: 73 | batch: 8] loss: 370.282\n",
      "[epoch: 73 | batch: 9] loss: 375.507\n",
      "[epoch: 73 | batch: 10] loss: 479.041\n",
      "[epoch: 73 | batch: 11] loss: 413.937\n",
      "[epoch: 73 | batch: 12] loss: 417.611\n",
      "[epoch: 73 | batch: 13] loss: 179.021\n",
      "mean epoch loss: 423.44\n",
      "saved model to ./model/colnet181105-21-34-27.pt\n",
      "End of epoch 73\n",
      "\n",
      "[epoch: 74 | batch: 1] loss: 389.983\n",
      "[epoch: 74 | batch: 2] loss: 416.206\n",
      "[epoch: 74 | batch: 3] loss: 406.969\n",
      "[epoch: 74 | batch: 4] loss: 643.046\n",
      "[epoch: 74 | batch: 5] loss: 376.028\n",
      "[epoch: 74 | batch: 6] loss: 484.944\n",
      "[epoch: 74 | batch: 7] loss: 504.054\n",
      "[epoch: 74 | batch: 8] loss: 365.361\n",
      "[epoch: 74 | batch: 9] loss: 366.145\n",
      "[epoch: 74 | batch: 10] loss: 473.022\n",
      "[epoch: 74 | batch: 11] loss: 419.327\n",
      "[epoch: 74 | batch: 12] loss: 415.230\n",
      "[epoch: 74 | batch: 13] loss: 180.274\n",
      "mean epoch loss: 418.51\n",
      "saved model to ./model/colnet181105-21-34-31.pt\n",
      "End of epoch 74\n",
      "\n",
      "[epoch: 75 | batch: 1] loss: 380.372\n",
      "[epoch: 75 | batch: 2] loss: 407.029\n",
      "[epoch: 75 | batch: 3] loss: 407.193\n",
      "[epoch: 75 | batch: 4] loss: 646.272\n",
      "[epoch: 75 | batch: 5] loss: 387.811\n",
      "[epoch: 75 | batch: 6] loss: 486.542\n",
      "[epoch: 75 | batch: 7] loss: 506.014\n",
      "[epoch: 75 | batch: 8] loss: 363.295\n",
      "[epoch: 75 | batch: 9] loss: 361.274\n",
      "[epoch: 75 | batch: 10] loss: 471.285\n",
      "[epoch: 75 | batch: 11] loss: 416.694\n",
      "[epoch: 75 | batch: 12] loss: 414.857\n",
      "[epoch: 75 | batch: 13] loss: 180.380\n",
      "mean epoch loss: 417.62\n",
      "saved model to ./model/colnet181105-21-34-35.pt\n",
      "End of epoch 75\n",
      "\n",
      "[epoch: 76 | batch: 1] loss: 383.533\n",
      "[epoch: 76 | batch: 2] loss: 407.061\n",
      "[epoch: 76 | batch: 3] loss: 405.909\n",
      "[epoch: 76 | batch: 4] loss: 643.383\n",
      "[epoch: 76 | batch: 5] loss: 388.919\n",
      "[epoch: 76 | batch: 6] loss: 489.846\n",
      "[epoch: 76 | batch: 7] loss: 500.428\n",
      "[epoch: 76 | batch: 8] loss: 362.731\n",
      "[epoch: 76 | batch: 9] loss: 362.733\n",
      "[epoch: 76 | batch: 10] loss: 469.154\n",
      "[epoch: 76 | batch: 11] loss: 416.912\n",
      "[epoch: 76 | batch: 12] loss: 414.755\n",
      "[epoch: 76 | batch: 13] loss: 178.180\n",
      "mean epoch loss: 417.20\n",
      "saved model to ./model/colnet181105-21-34-39.pt\n",
      "End of epoch 76\n",
      "\n",
      "[epoch: 77 | batch: 1] loss: 382.521\n",
      "[epoch: 77 | batch: 2] loss: 407.943\n",
      "[epoch: 77 | batch: 3] loss: 401.271\n",
      "[epoch: 77 | batch: 4] loss: 632.947\n",
      "[epoch: 77 | batch: 5] loss: 388.759\n",
      "[epoch: 77 | batch: 6] loss: 481.076\n",
      "[epoch: 77 | batch: 7] loss: 498.616\n",
      "[epoch: 77 | batch: 8] loss: 352.557\n",
      "[epoch: 77 | batch: 9] loss: 357.817\n",
      "[epoch: 77 | batch: 10] loss: 464.601\n",
      "[epoch: 77 | batch: 11] loss: 434.257\n",
      "[epoch: 77 | batch: 12] loss: 415.012\n",
      "[epoch: 77 | batch: 13] loss: 173.941\n",
      "mean epoch loss: 414.72\n",
      "saved model to ./model/colnet181105-21-34-43.pt\n",
      "End of epoch 77\n",
      "\n",
      "[epoch: 78 | batch: 1] loss: 381.844\n",
      "[epoch: 78 | batch: 2] loss: 406.025\n",
      "[epoch: 78 | batch: 3] loss: 421.664\n",
      "[epoch: 78 | batch: 4] loss: 647.515\n",
      "[epoch: 78 | batch: 5] loss: 388.181\n",
      "[epoch: 78 | batch: 6] loss: 475.939\n",
      "[epoch: 78 | batch: 7] loss: 510.704\n",
      "[epoch: 78 | batch: 8] loss: 387.721\n",
      "[epoch: 78 | batch: 9] loss: 362.547\n",
      "[epoch: 78 | batch: 10] loss: 469.315\n",
      "[epoch: 78 | batch: 11] loss: 409.169\n",
      "[epoch: 78 | batch: 12] loss: 414.640\n",
      "[epoch: 78 | batch: 13] loss: 184.336\n",
      "mean epoch loss: 419.97\n",
      "saved model to ./model/colnet181105-21-34-47.pt\n",
      "End of epoch 78\n",
      "\n",
      "[epoch: 79 | batch: 1] loss: 394.940\n",
      "[epoch: 79 | batch: 2] loss: 415.348\n",
      "[epoch: 79 | batch: 3] loss: 382.754\n",
      "[epoch: 79 | batch: 4] loss: 614.715\n",
      "[epoch: 79 | batch: 5] loss: 398.221\n",
      "[epoch: 79 | batch: 6] loss: 482.419\n",
      "[epoch: 79 | batch: 7] loss: 518.610\n",
      "[epoch: 79 | batch: 8] loss: 371.214\n",
      "[epoch: 79 | batch: 9] loss: 359.660\n",
      "[epoch: 79 | batch: 10] loss: 474.899\n",
      "[epoch: 79 | batch: 11] loss: 403.825\n",
      "[epoch: 79 | batch: 12] loss: 416.260\n",
      "[epoch: 79 | batch: 13] loss: 177.114\n",
      "mean epoch loss: 416.15\n",
      "saved model to ./model/colnet181105-21-34-51.pt\n",
      "End of epoch 79\n",
      "\n",
      "[epoch: 80 | batch: 1] loss: 392.762\n",
      "[epoch: 80 | batch: 2] loss: 423.228\n",
      "[epoch: 80 | batch: 3] loss: 387.532\n",
      "[epoch: 80 | batch: 4] loss: 620.916\n",
      "[epoch: 80 | batch: 5] loss: 385.510\n",
      "[epoch: 80 | batch: 6] loss: 473.129\n",
      "[epoch: 80 | batch: 7] loss: 517.023\n",
      "[epoch: 80 | batch: 8] loss: 366.012\n",
      "[epoch: 80 | batch: 9] loss: 356.789\n",
      "[epoch: 80 | batch: 10] loss: 469.224\n",
      "[epoch: 80 | batch: 11] loss: 397.710\n",
      "[epoch: 80 | batch: 12] loss: 413.481\n",
      "[epoch: 80 | batch: 13] loss: 178.055\n",
      "mean epoch loss: 413.95\n",
      "saved model to ./model/colnet181105-21-34-55.pt\n",
      "End of epoch 80\n",
      "\n",
      "[epoch: 81 | batch: 1] loss: 390.278\n",
      "[epoch: 81 | batch: 2] loss: 410.143\n",
      "[epoch: 81 | batch: 3] loss: 387.959\n",
      "[epoch: 81 | batch: 4] loss: 618.497\n",
      "[epoch: 81 | batch: 5] loss: 394.780\n",
      "[epoch: 81 | batch: 6] loss: 477.448\n",
      "[epoch: 81 | batch: 7] loss: 502.015\n",
      "[epoch: 81 | batch: 8] loss: 358.001\n",
      "[epoch: 81 | batch: 9] loss: 367.639\n",
      "[epoch: 81 | batch: 10] loss: 443.972\n",
      "[epoch: 81 | batch: 11] loss: 437.525\n",
      "[epoch: 81 | batch: 12] loss: 407.048\n",
      "[epoch: 81 | batch: 13] loss: 168.693\n",
      "mean epoch loss: 412.62\n",
      "saved model to ./model/colnet181105-21-35-00.pt\n",
      "End of epoch 81\n",
      "\n",
      "[epoch: 82 | batch: 1] loss: 383.934\n",
      "[epoch: 82 | batch: 2] loss: 407.481\n",
      "[epoch: 82 | batch: 3] loss: 438.215\n",
      "[epoch: 82 | batch: 4] loss: 640.164\n",
      "[epoch: 82 | batch: 5] loss: 364.435\n",
      "[epoch: 82 | batch: 6] loss: 466.489\n",
      "[epoch: 82 | batch: 7] loss: 501.976\n",
      "[epoch: 82 | batch: 8] loss: 380.536\n",
      "[epoch: 82 | batch: 9] loss: 377.149\n",
      "[epoch: 82 | batch: 10] loss: 471.998\n",
      "[epoch: 82 | batch: 11] loss: 411.459\n",
      "[epoch: 82 | batch: 12] loss: 409.908\n",
      "[epoch: 82 | batch: 13] loss: 187.894\n",
      "mean epoch loss: 418.59\n",
      "saved model to ./model/colnet181105-21-35-04.pt\n",
      "End of epoch 82\n",
      "\n",
      "[epoch: 83 | batch: 1] loss: 404.561\n",
      "[epoch: 83 | batch: 2] loss: 426.426\n",
      "[epoch: 83 | batch: 3] loss: 369.853\n",
      "[epoch: 83 | batch: 4] loss: 588.198\n",
      "[epoch: 83 | batch: 5] loss: 391.621\n",
      "[epoch: 83 | batch: 6] loss: 472.865\n",
      "[epoch: 83 | batch: 7] loss: 523.436\n",
      "[epoch: 83 | batch: 8] loss: 365.814\n",
      "[epoch: 83 | batch: 9] loss: 359.158\n",
      "[epoch: 83 | batch: 10] loss: 485.057\n",
      "[epoch: 83 | batch: 11] loss: 379.328\n",
      "[epoch: 83 | batch: 12] loss: 409.766\n",
      "[epoch: 83 | batch: 13] loss: 170.280\n",
      "mean epoch loss: 411.26\n",
      "saved model to ./model/colnet181105-21-35-08.pt\n",
      "End of epoch 83\n",
      "\n",
      "[epoch: 84 | batch: 1] loss: 392.832\n",
      "[epoch: 84 | batch: 2] loss: 426.400\n",
      "[epoch: 84 | batch: 3] loss: 382.133\n",
      "[epoch: 84 | batch: 4] loss: 599.680\n",
      "[epoch: 84 | batch: 5] loss: 374.310\n",
      "[epoch: 84 | batch: 6] loss: 461.366\n",
      "[epoch: 84 | batch: 7] loss: 507.983\n",
      "[epoch: 84 | batch: 8] loss: 368.954\n",
      "[epoch: 84 | batch: 9] loss: 362.859\n",
      "[epoch: 84 | batch: 10] loss: 466.005\n",
      "[epoch: 84 | batch: 11] loss: 392.567\n",
      "[epoch: 84 | batch: 12] loss: 406.510\n",
      "[epoch: 84 | batch: 13] loss: 174.635\n",
      "mean epoch loss: 408.94\n",
      "saved model to ./model/colnet181105-21-35-12.pt\n",
      "End of epoch 84\n",
      "\n",
      "[epoch: 85 | batch: 1] loss: 392.449\n",
      "[epoch: 85 | batch: 2] loss: 413.033\n",
      "[epoch: 85 | batch: 3] loss: 381.953\n",
      "[epoch: 85 | batch: 4] loss: 598.750\n",
      "[epoch: 85 | batch: 5] loss: 373.003\n",
      "[epoch: 85 | batch: 6] loss: 457.169\n",
      "[epoch: 85 | batch: 7] loss: 504.385\n",
      "[epoch: 85 | batch: 8] loss: 362.775\n",
      "[epoch: 85 | batch: 9] loss: 360.227\n",
      "[epoch: 85 | batch: 10] loss: 458.769\n",
      "[epoch: 85 | batch: 11] loss: 385.095\n",
      "[epoch: 85 | batch: 12] loss: 403.258\n",
      "[epoch: 85 | batch: 13] loss: 169.770\n",
      "mean epoch loss: 404.66\n",
      "saved model to ./model/colnet181105-21-35-16.pt\n",
      "End of epoch 85\n",
      "\n",
      "[epoch: 86 | batch: 1] loss: 386.940\n",
      "[epoch: 86 | batch: 2] loss: 410.785\n",
      "[epoch: 86 | batch: 3] loss: 381.175\n",
      "[epoch: 86 | batch: 4] loss: 590.204\n",
      "[epoch: 86 | batch: 5] loss: 366.220\n",
      "[epoch: 86 | batch: 6] loss: 451.705\n",
      "[epoch: 86 | batch: 7] loss: 491.552\n",
      "[epoch: 86 | batch: 8] loss: 349.178\n",
      "[epoch: 86 | batch: 9] loss: 360.782\n",
      "[epoch: 86 | batch: 10] loss: 459.812\n",
      "[epoch: 86 | batch: 11] loss: 379.837\n",
      "[epoch: 86 | batch: 12] loss: 397.532\n",
      "[epoch: 86 | batch: 13] loss: 169.566\n",
      "mean epoch loss: 399.64\n",
      "saved model to ./model/colnet181105-21-35-20.pt\n",
      "End of epoch 86\n",
      "\n",
      "[epoch: 87 | batch: 1] loss: 384.676\n",
      "[epoch: 87 | batch: 2] loss: 408.945\n",
      "[epoch: 87 | batch: 3] loss: 387.673\n",
      "[epoch: 87 | batch: 4] loss: 585.635\n",
      "[epoch: 87 | batch: 5] loss: 364.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 87 | batch: 6] loss: 457.231\n",
      "[epoch: 87 | batch: 7] loss: 489.074\n",
      "[epoch: 87 | batch: 8] loss: 351.952\n",
      "[epoch: 87 | batch: 9] loss: 364.288\n",
      "[epoch: 87 | batch: 10] loss: 454.716\n",
      "[epoch: 87 | batch: 11] loss: 378.384\n",
      "[epoch: 87 | batch: 12] loss: 394.196\n",
      "[epoch: 87 | batch: 13] loss: 163.835\n",
      "mean epoch loss: 398.89\n",
      "saved model to ./model/colnet181105-21-35-24.pt\n",
      "End of epoch 87\n",
      "\n",
      "[epoch: 88 | batch: 1] loss: 379.368\n",
      "[epoch: 88 | batch: 2] loss: 402.475\n",
      "[epoch: 88 | batch: 3] loss: 384.605\n",
      "[epoch: 88 | batch: 4] loss: 585.202\n",
      "[epoch: 88 | batch: 5] loss: 353.079\n",
      "[epoch: 88 | batch: 6] loss: 444.181\n",
      "[epoch: 88 | batch: 7] loss: 474.007\n",
      "[epoch: 88 | batch: 8] loss: 336.699\n",
      "[epoch: 88 | batch: 9] loss: 365.537\n",
      "[epoch: 88 | batch: 10] loss: 449.215\n",
      "[epoch: 88 | batch: 11] loss: 380.964\n",
      "[epoch: 88 | batch: 12] loss: 386.282\n",
      "[epoch: 88 | batch: 13] loss: 166.664\n",
      "mean epoch loss: 392.94\n",
      "saved model to ./model/colnet181105-21-35-28.pt\n",
      "End of epoch 88\n",
      "\n",
      "[epoch: 89 | batch: 1] loss: 373.622\n",
      "[epoch: 89 | batch: 2] loss: 401.140\n",
      "[epoch: 89 | batch: 3] loss: 382.957\n",
      "[epoch: 89 | batch: 4] loss: 582.040\n",
      "[epoch: 89 | batch: 5] loss: 360.618\n",
      "[epoch: 89 | batch: 6] loss: 442.665\n",
      "[epoch: 89 | batch: 7] loss: 467.522\n",
      "[epoch: 89 | batch: 8] loss: 326.956\n",
      "[epoch: 89 | batch: 9] loss: 355.557\n",
      "[epoch: 89 | batch: 10] loss: 454.434\n",
      "[epoch: 89 | batch: 11] loss: 377.928\n",
      "[epoch: 89 | batch: 12] loss: 385.958\n",
      "[epoch: 89 | batch: 13] loss: 163.351\n",
      "mean epoch loss: 390.37\n",
      "saved model to ./model/colnet181105-21-35-32.pt\n",
      "End of epoch 89\n",
      "\n",
      "[epoch: 90 | batch: 1] loss: 369.368\n",
      "[epoch: 90 | batch: 2] loss: 391.886\n",
      "[epoch: 90 | batch: 3] loss: 394.264\n",
      "[epoch: 90 | batch: 4] loss: 569.675\n",
      "[epoch: 90 | batch: 5] loss: 351.657\n",
      "[epoch: 90 | batch: 6] loss: 446.743\n",
      "[epoch: 90 | batch: 7] loss: 472.427\n",
      "[epoch: 90 | batch: 8] loss: 335.978\n",
      "[epoch: 90 | batch: 9] loss: 354.983\n",
      "[epoch: 90 | batch: 10] loss: 440.029\n",
      "[epoch: 90 | batch: 11] loss: 375.993\n",
      "[epoch: 90 | batch: 12] loss: 379.958\n",
      "[epoch: 90 | batch: 13] loss: 161.016\n",
      "mean epoch loss: 388.00\n",
      "saved model to ./model/colnet181105-21-35-36.pt\n",
      "End of epoch 90\n",
      "\n",
      "[epoch: 91 | batch: 1] loss: 368.978\n",
      "[epoch: 91 | batch: 2] loss: 391.775\n",
      "[epoch: 91 | batch: 3] loss: 393.100\n",
      "[epoch: 91 | batch: 4] loss: 567.016\n",
      "[epoch: 91 | batch: 5] loss: 346.547\n",
      "[epoch: 91 | batch: 6] loss: 436.725\n",
      "[epoch: 91 | batch: 7] loss: 458.601\n",
      "[epoch: 91 | batch: 8] loss: 320.777\n",
      "[epoch: 91 | batch: 9] loss: 356.379\n",
      "[epoch: 91 | batch: 10] loss: 435.293\n",
      "[epoch: 91 | batch: 11] loss: 390.295\n",
      "[epoch: 91 | batch: 12] loss: 378.304\n",
      "[epoch: 91 | batch: 13] loss: 156.548\n",
      "mean epoch loss: 384.64\n",
      "saved model to ./model/colnet181105-21-35-40.pt\n",
      "End of epoch 91\n",
      "\n",
      "[epoch: 92 | batch: 1] loss: 359.878\n",
      "[epoch: 92 | batch: 2] loss: 385.271\n",
      "[epoch: 92 | batch: 3] loss: 391.861\n",
      "[epoch: 92 | batch: 4] loss: 561.621\n",
      "[epoch: 92 | batch: 5] loss: 338.729\n",
      "[epoch: 92 | batch: 6] loss: 434.723\n",
      "[epoch: 92 | batch: 7] loss: 459.199\n",
      "[epoch: 92 | batch: 8] loss: 311.994\n",
      "[epoch: 92 | batch: 9] loss: 353.451\n",
      "[epoch: 92 | batch: 10] loss: 439.444\n",
      "[epoch: 92 | batch: 11] loss: 381.904\n",
      "[epoch: 92 | batch: 12] loss: 370.494\n",
      "[epoch: 92 | batch: 13] loss: 159.730\n",
      "mean epoch loss: 380.64\n",
      "saved model to ./model/colnet181105-21-35-44.pt\n",
      "End of epoch 92\n",
      "\n",
      "[epoch: 93 | batch: 1] loss: 351.837\n",
      "[epoch: 93 | batch: 2] loss: 375.328\n",
      "[epoch: 93 | batch: 3] loss: 391.437\n",
      "[epoch: 93 | batch: 4] loss: 561.888\n",
      "[epoch: 93 | batch: 5] loss: 353.506\n",
      "[epoch: 93 | batch: 6] loss: 437.202\n",
      "[epoch: 93 | batch: 7] loss: 453.294\n",
      "[epoch: 93 | batch: 8] loss: 311.209\n",
      "[epoch: 93 | batch: 9] loss: 343.404\n",
      "[epoch: 93 | batch: 10] loss: 434.712\n",
      "[epoch: 93 | batch: 11] loss: 379.767\n",
      "[epoch: 93 | batch: 12] loss: 372.755\n",
      "[epoch: 93 | batch: 13] loss: 163.252\n",
      "mean epoch loss: 379.20\n",
      "saved model to ./model/colnet181105-21-35-49.pt\n",
      "End of epoch 93\n",
      "\n",
      "[epoch: 94 | batch: 1] loss: 355.967\n",
      "[epoch: 94 | batch: 2] loss: 375.284\n",
      "[epoch: 94 | batch: 3] loss: 386.719\n",
      "[epoch: 94 | batch: 4] loss: 558.618\n",
      "[epoch: 94 | batch: 5] loss: 355.282\n",
      "[epoch: 94 | batch: 6] loss: 434.143\n",
      "[epoch: 94 | batch: 7] loss: 453.514\n",
      "[epoch: 94 | batch: 8] loss: 317.764\n",
      "[epoch: 94 | batch: 9] loss: 344.143\n",
      "[epoch: 94 | batch: 10] loss: 426.138\n",
      "[epoch: 94 | batch: 11] loss: 387.236\n",
      "[epoch: 94 | batch: 12] loss: 369.091\n",
      "[epoch: 94 | batch: 13] loss: 169.948\n",
      "mean epoch loss: 379.53\n",
      "saved model to ./model/colnet181105-21-35-53.pt\n",
      "End of epoch 94\n",
      "\n",
      "[epoch: 95 | batch: 1] loss: 362.384\n",
      "[epoch: 95 | batch: 2] loss: 386.048\n",
      "[epoch: 95 | batch: 3] loss: 397.285\n",
      "[epoch: 95 | batch: 4] loss: 556.381\n",
      "[epoch: 95 | batch: 5] loss: 346.131\n",
      "[epoch: 95 | batch: 6] loss: 439.298\n",
      "[epoch: 95 | batch: 7] loss: 462.197\n",
      "[epoch: 95 | batch: 8] loss: 336.778\n",
      "[epoch: 95 | batch: 9] loss: 348.873\n",
      "[epoch: 95 | batch: 10] loss: 434.438\n",
      "[epoch: 95 | batch: 11] loss: 369.880\n",
      "[epoch: 95 | batch: 12] loss: 369.779\n",
      "[epoch: 95 | batch: 13] loss: 161.611\n",
      "mean epoch loss: 382.39\n",
      "saved model to ./model/colnet181105-21-35-57.pt\n",
      "End of epoch 95\n",
      "\n",
      "[epoch: 96 | batch: 1] loss: 366.699\n",
      "[epoch: 96 | batch: 2] loss: 408.356\n",
      "[epoch: 96 | batch: 3] loss: 384.511\n",
      "[epoch: 96 | batch: 4] loss: 531.279\n",
      "[epoch: 96 | batch: 5] loss: 333.094\n",
      "[epoch: 96 | batch: 6] loss: 428.296\n",
      "[epoch: 96 | batch: 7] loss: 452.183\n",
      "[epoch: 96 | batch: 8] loss: 315.144\n",
      "[epoch: 96 | batch: 9] loss: 340.884\n",
      "[epoch: 96 | batch: 10] loss: 445.294\n",
      "[epoch: 96 | batch: 11] loss: 366.340\n",
      "[epoch: 96 | batch: 12] loss: 375.762\n",
      "[epoch: 96 | batch: 13] loss: 160.806\n",
      "mean epoch loss: 377.59\n",
      "saved model to ./model/colnet181105-21-36-01.pt\n",
      "End of epoch 96\n",
      "\n",
      "[epoch: 97 | batch: 1] loss: 352.889\n",
      "[epoch: 97 | batch: 2] loss: 381.798\n",
      "[epoch: 97 | batch: 3] loss: 364.146\n",
      "[epoch: 97 | batch: 4] loss: 509.982\n",
      "[epoch: 97 | batch: 5] loss: 333.821\n",
      "[epoch: 97 | batch: 6] loss: 431.656\n",
      "[epoch: 97 | batch: 7] loss: 438.759\n",
      "[epoch: 97 | batch: 8] loss: 294.489\n",
      "[epoch: 97 | batch: 9] loss: 335.384\n",
      "[epoch: 97 | batch: 10] loss: 441.527\n",
      "[epoch: 97 | batch: 11] loss: 344.376\n",
      "[epoch: 97 | batch: 12] loss: 366.331\n",
      "[epoch: 97 | batch: 13] loss: 142.679\n",
      "mean epoch loss: 364.45\n",
      "saved model to ./model/colnet181105-21-36-06.pt\n",
      "End of epoch 97\n",
      "\n",
      "[epoch: 98 | batch: 1] loss: 347.688\n",
      "[epoch: 98 | batch: 2] loss: 365.239\n",
      "[epoch: 98 | batch: 3] loss: 396.487\n",
      "[epoch: 98 | batch: 4] loss: 513.238\n",
      "[epoch: 98 | batch: 5] loss: 343.190\n",
      "[epoch: 98 | batch: 6] loss: 426.710\n",
      "[epoch: 98 | batch: 7] loss: 422.031\n",
      "[epoch: 98 | batch: 8] loss: 305.962\n",
      "[epoch: 98 | batch: 9] loss: 339.791\n",
      "[epoch: 98 | batch: 10] loss: 424.111\n",
      "[epoch: 98 | batch: 11] loss: 347.342\n",
      "[epoch: 98 | batch: 12] loss: 362.777\n",
      "[epoch: 98 | batch: 13] loss: 140.827\n",
      "mean epoch loss: 364.26\n",
      "saved model to ./model/colnet181105-21-36-11.pt\n",
      "End of epoch 98\n",
      "\n",
      "[epoch: 99 | batch: 1] loss: 343.980\n",
      "[epoch: 99 | batch: 2] loss: 364.479\n",
      "[epoch: 99 | batch: 3] loss: 392.993\n",
      "[epoch: 99 | batch: 4] loss: 527.740\n",
      "[epoch: 99 | batch: 5] loss: 330.219\n",
      "[epoch: 99 | batch: 6] loss: 405.407\n",
      "[epoch: 99 | batch: 7] loss: 415.042\n",
      "[epoch: 99 | batch: 8] loss: 295.280\n",
      "[epoch: 99 | batch: 9] loss: 334.736\n",
      "[epoch: 99 | batch: 10] loss: 414.790\n",
      "[epoch: 99 | batch: 11] loss: 373.366\n",
      "[epoch: 99 | batch: 12] loss: 353.890\n",
      "[epoch: 99 | batch: 13] loss: 143.954\n",
      "mean epoch loss: 361.22\n",
      "saved model to ./model/colnet181105-21-36-15.pt\n",
      "End of epoch 99\n",
      "\n",
      "[epoch: 100 | batch: 1] loss: 341.072\n",
      "[epoch: 100 | batch: 2] loss: 364.841\n",
      "[epoch: 100 | batch: 3] loss: 379.422\n",
      "[epoch: 100 | batch: 4] loss: 527.528\n",
      "[epoch: 100 | batch: 5] loss: 336.647\n",
      "[epoch: 100 | batch: 6] loss: 416.240\n",
      "[epoch: 100 | batch: 7] loss: 435.824\n",
      "[epoch: 100 | batch: 8] loss: 309.962\n",
      "[epoch: 100 | batch: 9] loss: 335.598\n",
      "[epoch: 100 | batch: 10] loss: 419.840\n",
      "[epoch: 100 | batch: 11] loss: 362.927\n",
      "[epoch: 100 | batch: 12] loss: 352.569\n",
      "[epoch: 100 | batch: 13] loss: 152.792\n",
      "mean epoch loss: 364.25\n",
      "saved model to ./model/colnet181105-21-36-20.pt\n",
      "End of epoch 100\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = ColNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "model_filename = \"\"\n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        L, ab, _ = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ab_outputs = net(L)\n",
    "        \n",
    "        loss = criterion(ab, ab_outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        print('[epoch: {} | batch: {}] loss: {:.3f}'\n",
    "              .format(epoch + 1, i + 1, running_loss / BATCH_SIZE))\n",
    "    \n",
    "        epoch_loss += running_loss\n",
    "    \n",
    "    print('mean epoch loss: {:.2f}'.format(epoch_loss / (BATCH_SIZE * len(trainloader))))\n",
    "        \n",
    "    # Save\n",
    "    model_filename = './model/colnet{}.pt'.format(time.strftime(\"%y%m%d-%H-%M-%S\"))\n",
    "    # model_filename = './model/colnet.pt'\n",
    "    torch.save(net.state_dict(), model_filename)\n",
    "    print('saved model to {}'.format(model_filename))\n",
    "    \n",
    "    print('End of epoch {}\\n'.format(epoch + 1))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf out/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you're using up to date model!!!\n",
      "Colorizing ./data/food41-120-test/ using ./model/colnet181105-21-36-20.pt\n",
      "\n",
      "Processing batch 1 / 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przezmek/.local/lib/python3.6/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2 / 3\n",
      "Processing batch 3 / 3\n",
      "Saved all photos to ./out/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przezmek/.local/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "model_filename = \"./model/colnet181105-21-36-20.pt\"\n",
    "\n",
    "print(\"Make sure you're using up to date model!!!\")    \n",
    "\n",
    "net = ColNet()\n",
    "net.load_state_dict(torch.load(model_filename))\n",
    "net.eval()\n",
    "\n",
    "print(\"Colorizing {} using {}\\n\".format(img_dir_test, model_filename))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_no, data in enumerate(testloader):\n",
    "        \n",
    "        print(\"Processing batch {} / {}\".format(batch_no + 1, len(testloader)))\n",
    "        L, ab, name = data\n",
    "        ab_outputs = net(L)\n",
    "        \n",
    "        for i in range(L.shape[0]):\n",
    "            img = net_out2rgb(L[i], ab_outputs[i])\n",
    "            io.imsave(os.path.join(\"./out/\", name[i]), img)\n",
    "\n",
    "print(\"Saved all photos to ./out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
