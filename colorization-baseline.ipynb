{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from skimage import color, io\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [x] convert dataset to tensor? (now: numpy array)\n",
    " - seems like dataloader does it automatically - but doesnt swap axes\n",
    " - transforms.toTensor does the job\n",
    "- [x] normialize data?\n",
    " - only $ab$ channel \n",
    "- [ ] transform images? - random crops itp\n",
    "- [ ] on deploy, increase num_workers in dataloader (>1)\n",
    "- [ ] deal with `torch.set_default_tensor_type('torch.DoubleTensor')`\n",
    "- [ ] should I use `torch.nn.functional.{relu | sigmoid}` or just `torch.nn.*`?\n",
    "- [x] refector asserts so they work with batch sizes different than 4\n",
    "- [ ] shuffle data (trainloader)\n",
    "- [ ] refactor?? - separate files\n",
    "- [ ] load / save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and convert them to [*CIE Lab*](https://en.m.wikipedia.org/wiki/CIELAB_color_space) color space\n",
    "\n",
    "Warrning: `OpenCV` [uses](https://stackoverflow.com/questions/39316447/opencv-giving-wrong-color-to-colored-images-on-loading) BGR scheme, whereas `matplotlib` uses RGB. `scikit-image` uses RGB as well.\n",
    "\n",
    "\n",
    "[Scikit color ranges: L: 0 to 100, a: -127 to 128, b: -128 to 127.](https://stackoverflow.com/questions/25294141/cielab-color-range-for-scikit-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom dateset\n",
    "\n",
    "Notes\n",
    "\n",
    "One needs to [swap axes](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms)\n",
    "- numpy image: H x W x C\n",
    "- torch image: C X H X W\n",
    "\n",
    "\n",
    "Quick facts: $L \\in [0, 100]$, $a \\in [-127, 128]$, $b \\in [-128, 127]$\n",
    "\n",
    "How an image is processed:\n",
    "1. Load i-th image to memory\n",
    "2. Convert it to LAB Space\n",
    "3. Convert to torch.tensor\n",
    "4. Split the image to $L$ and $ab$ channels\n",
    "5. Normalize $ab$ to $[0, 1]$. $L$ remains unnormalized.\n",
    "6. $L$ will feed net, $a'b'$ will be its output\n",
    "7. Calculate $Loss(ab, a'b')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDateset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir):\n",
    "        \"\"\"\n",
    "        All images from `img_dir` will be read.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = [file for file in os.listdir(self.img_dir)]\n",
    "        \n",
    "        assert all([img.endswith('.jpg') for img in self.img_names]), \"Must be *.jpg\"\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get an image in Lab color space.\n",
    "        Returns a tuple (L, ab)\n",
    "            - `L` stands for lightness - it's the net input\n",
    "            - `ab` is chrominance - something that the net learns\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        \n",
    "        assert image.shape == (224, 224, 3)\n",
    "                \n",
    "        img_lab = color.rgb2lab(image)\n",
    "        img_lab = np.transpose(img_lab, (2, 0, 1))\n",
    "        \n",
    "        assert img_lab.shape == (3, 224, 224)\n",
    "        \n",
    "        img_lab = torch.tensor( img_lab.astype(np.float32) )\n",
    "        \n",
    "        assert img_lab.shape == (3, 224, 224)\n",
    "               \n",
    "        L  = img_lab[:1,:,:]\n",
    "        ab = img_lab[1:,:,:]\n",
    "        \n",
    "        # Normalization\n",
    "        L = L/128.0   # 0..1\n",
    "        ab = (ab+128) / 255.0 # -1 .. 1\n",
    "              \n",
    "        assert L.shape == (1, 224, 224)\n",
    "        assert ab.shape == (2, 224, 224)\n",
    "        \n",
    "        return (L, ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_train ='./data/apple_pie//'\n",
    "img_dir_test = './data/apple_pie/'\n",
    "\n",
    "trainset = ImagesDateset(img_dir_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "\n",
    "testset = ImagesDateset(img_dir_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2,4])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        ksize = np.array( [1, 64, 128, 128, 256, 256, 512, 512, 256, 128, 64, 64, 32] ) // 8\n",
    "        ksize[0] = 1\n",
    "#         ksize = [1, 32, 128, 128, 256, 256, 512, 512, 256, 128, 64, 64, 32]\n",
    "        super(Net, self).__init__()\n",
    "        # 'Low-level features'\n",
    "        # conv1 has only one in channel - because it's only L channel of a photo\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,        out_channels=ksize[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=ksize[1], out_channels=ksize[2], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=ksize[2], out_channels=ksize[3], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=ksize[3], out_channels=ksize[4], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=ksize[4], out_channels=ksize[5], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=ksize[5], out_channels=ksize[6], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 'Mid-level fetures'\n",
    "        self.conv7 = nn.Conv2d(in_channels=ksize[6], out_channels=ksize[7], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=ksize[7], out_channels=ksize[8], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 'Colorization network'\n",
    "        self.conv9 = nn.Conv2d(in_channels=ksize[8], out_channels=ksize[9], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Here comes upsample #1\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(in_channels=ksize[9], out_channels=ksize[10], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(in_channels=ksize[10],out_channels=ksize[11], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Here comes upsample #2        \n",
    "        \n",
    "        self.conv12 = nn.Conv2d(in_channels=ksize[11], out_channels=ksize[12], kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv13out = nn.Conv2d(in_channels=ksize[12], out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Low level\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        \n",
    "        # Mid level\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        \n",
    "#         assert x.shape[1:] == (256, 28, 28), \"おわり： mid level\"\n",
    "        \n",
    "\n",
    "        # Colorization Net\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "#         assert x.shape[1:] == (128, 28, 28), \"おわり： conv9\"\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "\n",
    "#         assert x.shape[1:] == (128, 56, 56), \"おわり： upsample1\"\n",
    "    \n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.relu(self.conv11(x))\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = torch.sigmoid(self.conv13out(x))\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "        \n",
    "#         assert x.shape[1:] == (2, 224, 224)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_out2rgb(L, ab_out):\n",
    "    \"\"\"\n",
    "    L - original `L` channel\n",
    "    ab_out - learned `ab` channels which were the net's output\n",
    "    \n",
    "    Retruns: 3 channel RGB image\n",
    "    \"\"\"\n",
    "    # Convert to numpy and unnnormalize\n",
    "    L = L.numpy() * 128.0\n",
    "    \n",
    "    ab_out = ab_out.numpy() * 256.0 - 128.0\n",
    "    \n",
    "    # Transpose axis to HxWxC again\n",
    "    L = L.transpose((1, 2, 0))\n",
    "    ab_out = ab_out.transpose((1, 2, 0))\n",
    "\n",
    "    # Stack layers\n",
    "    lab_stack = np.dstack((L, ab_out))\n",
    "    \n",
    "    return color.lab2rgb(lab_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 1375.594\n",
      "[1,     2] loss: 1326.204\n",
      "[1,     3] loss: 1378.108\n",
      "[1,     4] loss: 1413.406\n",
      "[1,     5] loss: 1054.143\n",
      "[1,     6] loss: 1019.315\n",
      "[1,     7] loss: 1030.867\n",
      "[1,     8] loss: 918.058\n",
      "[1,     9] loss: 740.116\n",
      "[1,    10] loss: 400.310\n",
      "[1,    11] loss: 383.798\n",
      "[1,    12] loss: 629.999\n",
      "[1,    13] loss: 503.124\n",
      "[1,    14] loss: 361.580\n",
      "[1,    15] loss: 402.080\n",
      "[1,    16] loss: 490.566\n",
      "[1,    17] loss: 575.011\n",
      "[1,    18] loss: 597.113\n",
      "[1,    19] loss: 648.988\n",
      "[1,    20] loss: 435.035\n",
      "[1,    21] loss: 477.658\n",
      "[1,    22] loss: 318.393\n",
      "[1,    23] loss: 549.432\n",
      "[1,    24] loss: 424.274\n",
      "[1,    25] loss: 451.949\n",
      "[1,    26] loss: 461.863\n",
      "[1,    27] loss: 424.949\n",
      "[1,    28] loss: 349.140\n",
      "[1,    29] loss: 464.093\n",
      "[1,    30] loss: 210.156\n",
      "epoch loss [1] loss: 0.000\n",
      "End of epoch 0\n",
      "[2,     1] loss: 443.143\n",
      "[2,     2] loss: 488.819\n",
      "[2,     3] loss: 505.988\n",
      "[2,     4] loss: 551.310\n",
      "[2,     5] loss: 365.880\n",
      "[2,     6] loss: 365.141\n",
      "[2,     7] loss: 405.466\n",
      "[2,     8] loss: 486.333\n",
      "[2,     9] loss: 493.775\n",
      "[2,    10] loss: 363.517\n",
      "[2,    11] loss: 379.593\n",
      "[2,    12] loss: 408.332\n",
      "[2,    13] loss: 413.159\n",
      "[2,    14] loss: 352.293\n",
      "[2,    15] loss: 385.174\n",
      "[2,    16] loss: 405.737\n",
      "[2,    17] loss: 411.936\n",
      "[2,    18] loss: 416.185\n",
      "[2,    19] loss: 447.853\n",
      "[2,    20] loss: 367.121\n",
      "[2,    21] loss: 438.451\n",
      "[2,    22] loss: 360.559\n",
      "[2,    23] loss: 559.509\n",
      "[2,    24] loss: 401.046\n",
      "[2,    25] loss: 424.688\n",
      "[2,    26] loss: 397.132\n",
      "[2,    27] loss: 408.032\n",
      "[2,    28] loss: 354.305\n",
      "[2,    29] loss: 470.123\n",
      "[2,    30] loss: 207.662\n",
      "epoch loss [2] loss: 0.031\n",
      "End of epoch 1\n",
      "[3,     1] loss: 391.357\n",
      "[3,     2] loss: 439.398\n",
      "[3,     3] loss: 449.383\n",
      "[3,     4] loss: 521.165\n",
      "[3,     5] loss: 399.105\n",
      "[3,     6] loss: 385.177\n",
      "[3,     7] loss: 397.384\n",
      "[3,     8] loss: 452.895\n",
      "[3,     9] loss: 453.411\n",
      "[3,    10] loss: 329.403\n",
      "[3,    11] loss: 408.921\n",
      "[3,    12] loss: 442.203\n",
      "[3,    13] loss: 421.867\n",
      "[3,    14] loss: 348.315\n",
      "[3,    15] loss: 368.120\n",
      "[3,    16] loss: 388.262\n",
      "[3,    17] loss: 388.952\n",
      "[3,    18] loss: 409.815\n",
      "[3,    19] loss: 447.564\n",
      "[3,    20] loss: 379.003\n",
      "[3,    21] loss: 427.818\n",
      "[3,    22] loss: 331.129\n",
      "[3,    23] loss: 542.327\n",
      "[3,    24] loss: 412.597\n",
      "[3,    25] loss: 443.630\n",
      "[3,    26] loss: 403.114\n",
      "[3,    27] loss: 409.632\n",
      "[3,    28] loss: 350.802\n",
      "[3,    29] loss: 459.995\n",
      "[3,    30] loss: 209.175\n",
      "epoch loss [3] loss: 0.062\n",
      "End of epoch 2\n",
      "[4,     1] loss: 373.559\n",
      "[4,     2] loss: 437.026\n",
      "[4,     3] loss: 448.449\n",
      "[4,     4] loss: 519.947\n",
      "[4,     5] loss: 389.917\n",
      "[4,     6] loss: 369.296\n",
      "[4,     7] loss: 389.770\n",
      "[4,     8] loss: 450.054\n",
      "[4,     9] loss: 454.385\n",
      "[4,    10] loss: 331.875\n",
      "[4,    11] loss: 400.171\n",
      "[4,    12] loss: 426.910\n",
      "[4,    13] loss: 408.274\n",
      "[4,    14] loss: 344.202\n",
      "[4,    15] loss: 361.147\n",
      "[4,    16] loss: 387.500\n",
      "[4,    17] loss: 384.440\n",
      "[4,    18] loss: 409.487\n",
      "[4,    19] loss: 443.163\n",
      "[4,    20] loss: 365.869\n",
      "[4,    21] loss: 418.607\n",
      "[4,    22] loss: 322.188\n",
      "[4,    23] loss: 539.484\n",
      "[4,    24] loss: 412.310\n",
      "[4,    25] loss: 436.790\n",
      "[4,    26] loss: 393.914\n",
      "[4,    27] loss: 398.884\n",
      "[4,    28] loss: 342.347\n",
      "[4,    29] loss: 450.350\n",
      "[4,    30] loss: 210.135\n",
      "epoch loss [4] loss: 0.094\n",
      "End of epoch 3\n",
      "[5,     1] loss: 365.161\n",
      "[5,     2] loss: 430.886\n",
      "[5,     3] loss: 441.805\n",
      "[5,     4] loss: 501.447\n",
      "[5,     5] loss: 375.796\n",
      "[5,     6] loss: 359.584\n",
      "[5,     7] loss: 380.166\n",
      "[5,     8] loss: 444.781\n",
      "[5,     9] loss: 448.723\n",
      "[5,    10] loss: 332.689\n",
      "[5,    11] loss: 385.036\n",
      "[5,    12] loss: 402.618\n",
      "[5,    13] loss: 390.184\n",
      "[5,    14] loss: 332.666\n",
      "[5,    15] loss: 348.761\n",
      "[5,    16] loss: 381.177\n",
      "[5,    17] loss: 369.933\n",
      "[5,    18] loss: 400.258\n",
      "[5,    19] loss: 435.880\n",
      "[5,    20] loss: 350.244\n",
      "[5,    21] loss: 408.914\n",
      "[5,    22] loss: 313.368\n",
      "[5,    23] loss: 529.955\n",
      "[5,    24] loss: 403.961\n",
      "[5,    25] loss: 417.858\n",
      "[5,    26] loss: 375.895\n",
      "[5,    27] loss: 384.719\n",
      "[5,    28] loss: 335.335\n",
      "[5,    29] loss: 433.964\n",
      "[5,    30] loss: 208.146\n",
      "epoch loss [5] loss: 0.125\n",
      "End of epoch 4\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(5): \n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        L, ab = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ab_outputs = net(L)\n",
    "        \n",
    "        loss = criterion(ab, ab_outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "#         if i % 2000 == 1999:    \n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 32))\n",
    "    \n",
    "        epoch_loss += running_loss\n",
    "    \n",
    "    print('epoch loss [%d] loss: %.3f' %\n",
    "              (epoch + 1, epoch / 32))\n",
    "    print('End of epoch {}'.format(epoch))\n",
    "    torch.save(net.state_dict(), './model/colnet' + time.strftime(\"%y%m%d-%H-%M-%S\") + \".pt\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './data/colnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przezmek/.local/lib/python3.6/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/przezmek/.local/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('./model/colnet181030-13-32-54.pt'))\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "\n",
    "        L, ab = data\n",
    "        ab_outputs = net(L)\n",
    "        \n",
    "        for i in range(L.shape[0]):\n",
    "            print(i)\n",
    "            img = net_out2rgb(L[i], ab_outputs[i])\n",
    "            io.imsave(\"./out/{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
