{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from skimage import color, io\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [x] convert dataset to tensor? (now: numpy array)\n",
    " - seems like dataloader does it automatically - but doesnt swap axes\n",
    " - transforms.toTensor does the job\n",
    "- [x] normialize data?\n",
    " - only $ab$ channel \n",
    "- [ ] transform images? - random crops itp\n",
    "- [ ] on deploy, increase num_workers in dataloader (>1)\n",
    "- [ ] deal with `torch.set_default_tensor_type('torch.DoubleTensor')`\n",
    "- [ ] should I use `torch.nn.functional.{relu | sigmoid}` or just `torch.nn.*`?\n",
    "- [x] refector asserts so they work with batch sizes different than 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and convert them to [*CIE Lab*](https://en.m.wikipedia.org/wiki/CIELAB_color_space) color space\n",
    "\n",
    "Warrning: `OpenCV` [uses](https://stackoverflow.com/questions/39316447/opencv-giving-wrong-color-to-colored-images-on-loading) BGR scheme, whereas `matplotlib` uses RGB. `scikit-image` uses RGB as well.\n",
    "\n",
    "\n",
    "[Scikit color ranges: L: 0 to 100, a: -127 to 128, b: -128 to 127.](https://stackoverflow.com/questions/25294141/cielab-color-range-for-scikit-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom dateset\n",
    "\n",
    "Notes\n",
    "\n",
    "One needs to [swap axes](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms)\n",
    "- numpy image: H x W x C\n",
    "- torch image: C X H X W\n",
    "\n",
    "\n",
    "Quick facts: $L \\in [0, 100]$, $a \\in [-127, 128]$, $b \\in [-128, 127]$\n",
    "\n",
    "How an image is processed:\n",
    "1. Load i-th image to memory\n",
    "2. Convert it to LAB Space\n",
    "3. Convert to torch.tensor\n",
    "4. Split the image to $L$ and $ab$ channels\n",
    "5. Normalize $ab$ to $[0, 1]$. $L$ remains unnormalized.\n",
    "6. $L$ will feed net, $a'b'$ will be its output\n",
    "7. Calculate $Loss(ab, a'b')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDateset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir):\n",
    "        \"\"\"\n",
    "        All images from `img_dir` will be read.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = [file for file in os.listdir(self.img_dir)]\n",
    "        \n",
    "        assert all([img.endswith('.jpg') for img in self.img_names]), \"Must be *.jpg\"\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get an image in Lab color space.\n",
    "        Returns a tuple (L, ab)\n",
    "            - `L` stands for lightness - it's the net input\n",
    "            - `ab` is chrominance - something that the net learns\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        assert image.shape == (224, 224, 3)\n",
    "                \n",
    "        img_lab = color.rgb2lab(image)\n",
    "        \n",
    "        tsfm2tensor = transforms.ToTensor()\n",
    "        \n",
    "        img_lab = tsfm2tensor(img_lab)        \n",
    "        img_lab = img_lab.double()\n",
    "        \n",
    "        assert img_lab.shape == (3, 224, 224)\n",
    "               \n",
    "        L  = img_lab[:1,:,:]\n",
    "        ab = img_lab[1:,:,:]\n",
    "        \n",
    "        # Normalize to (0, 1)\n",
    "        ab = (ab + 128.0) / 256.0\n",
    "              \n",
    "        assert L.shape == (1, 224, 224)\n",
    "        assert ab.shape == (2, 224, 224)\n",
    "        \n",
    "        return (L, ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir='./data/rawcropped224/'\n",
    "\n",
    "trainset = ImagesDateset(img_dir)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 'Low-level features'\n",
    "        # conv1 has only one in channel - because it's only L channel of a photo\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 'Mid-level fetures'\n",
    "        self.conv7 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 'Colorization network'\n",
    "        self.conv9 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Here comes upsample #1\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(in_channels=64,  out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Here comes upsample #2        \n",
    "        \n",
    "        self.conv12 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.conv13out = nn.Conv2d(in_channels=32, out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Low level\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        \n",
    "        # Mid level\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        \n",
    "        assert x.shape[1:] == (256, 28, 28), \"おわり： mid level\"\n",
    "        \n",
    "\n",
    "        # Colorization Net\n",
    "        x = F.relu(self.conv9(x))\n",
    "        \n",
    "        assert x.shape[1:] == (128, 28, 28), \"おわり： conv9\"\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "\n",
    "        assert x.shape[1:] == (128, 56, 56), \"おわり： upsample1\"\n",
    "    \n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.relu(self.conv11(x))\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = torch.sigmoid(self.conv13out(x))\n",
    "        \n",
    "        x = nn.functional.interpolate(input=x, scale_factor=2, mode='nearest')\n",
    "        \n",
    "        assert x.shape[1:] == (2, 224, 224)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(2): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # inputs, labels = data\n",
    "        L, ab = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ab_outputs = net(L)\n",
    "        \n",
    "        loss = criterion(ab, ab_outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    \n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conert to numpy array and map to AB range\n",
    "out_np = out[1].detach().numpy() * 256 - 128.0\n",
    "\n",
    "# Take L channel and convert to numpy\n",
    "Lnew = L[1].numpy()\n",
    "\n",
    "# Transpose axis to HxWxC again\n",
    "Lnew = Lnew.transpose((1, 2, 0))\n",
    "out_np = out_np.transpose((1, 2, 0))     \n",
    "\n",
    "print(Lnew.shape)\n",
    "print(type(Lnew))\n",
    "print(out_np.shape)\n",
    "print(type(out_np))\n",
    "\n",
    "\n",
    "# Stack layers\n",
    "LABstackeed = np.dstack((Lnew, out_np))\n",
    "\n",
    "print(\"lab_ok.shape\")\n",
    "print(LABstackeed.shape)\n",
    "\n",
    "# Print img\n",
    "io.imshow(color.lab2rgb(LABstackeed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
